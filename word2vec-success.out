Using TensorFlow backend.
['\n', 'the', 'adventures', 'of', 'sherlock', 'holmes', 'by']
[4, 5, 1617, 9, 199, 36, 54]
[[2491, 6540], [128, 13599], [100, 16984], [967, 9446], [10811, 16], [14405, 6941], [368, 10], [5051, 10], [4070, 3597], [9314, 736]] [0, 0, 0, 0, 1, 0, 1, 1, 1, 0]
2018-12-06 22:27:06.337213: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
Iteration 0, loss=0.6955606341362
Nearest to that: muskets, rupee, post-bag, distrust, butter-dishes, jerked, adjoining, impresses,
Nearest to the: moaning, churchman, ajar, victor, state, escapade, moorside, journeys,
Nearest to my: spear, lintel, concert, resided, pen-knife, constabulary, volcanic, ornaments,
Nearest to before: accessible, freebody, stood, carriage, brassy, spindled, sloped, purview,
Nearest to !: field, dictates, hath, unclasped, unwieldy, voice, sleuth-hound, atone,
Nearest to if: morphy, spindled, dictionary, powder-barrel, mistaking, bruce-partington, lounged, individual,
Nearest to could: somnolence, condyle, lat, interpreter's, whereabouts, wakened, gamblingden, surly,
Nearest to .: prominence, crushed, conflagration, beddington, gibson, appeal, duke's, transaction,
Nearest to over: depose, flame-like, resentment, awe, uncarpeted, lifting, dissecting-rooms, easy,
Nearest to what: tight, breast-high, constables, assist, procedure, bespectacled, decanters, humble,
Nearest to when: ramifications, stitches, parisian, bursting, waits, sanger, use, unsettling,
Nearest to time: lookout, dislike, alliance, cottages, finance, scrutinized, miry, penny,
Nearest to ?: audible, rearranging, clapham, grassland, prudence, occupied, pseudo-leprosy, calmer,
Nearest to up: epidemic, observes, castles, game-shot, bowery, well-nigh, non-commissioned, sidled,
Nearest to am: culminating, stipulated, unfolding, twitching, bent, thirtieth, rueful, exhaustion,
Nearest to but: sovereign, ribs, wood-flooring, courting, harris, university, cabaret, roared,
Iteration 100, loss=0.6906264424324036
Iteration 200, loss=0.6958982944488525
Iteration 300, loss=0.7081331610679626
Iteration 400, loss=0.6966812014579773
Iteration 500, loss=0.6843248009681702
Iteration 600, loss=0.6953351497650146
Iteration 700, loss=0.689408540725708
Iteration 800, loss=0.6738839745521545
Iteration 900, loss=0.69711834192276
Iteration 1000, loss=0.674142599105835
Iteration 1100, loss=0.7023007273674011
Iteration 1200, loss=0.7050284147262573
Iteration 1300, loss=0.672103226184845
Iteration 1400, loss=0.6977708339691162
Iteration 1500, loss=0.6670440435409546
Iteration 1600, loss=0.7057895064353943
Iteration 1700, loss=0.6821144223213196
Iteration 1800, loss=0.7234777808189392
Iteration 1900, loss=0.6736975908279419
Iteration 2000, loss=0.6821252703666687
Iteration 2100, loss=0.7436536550521851
Iteration 2200, loss=0.6900617480278015
Iteration 2300, loss=0.6692321300506592
Iteration 2400, loss=0.6697970032691956
Iteration 2500, loss=0.7067516446113586
Iteration 2600, loss=0.6626449227333069
Iteration 2700, loss=0.7463488578796387
Iteration 2800, loss=0.6836183667182922
Iteration 2900, loss=0.66813725233078
Iteration 3000, loss=0.6865920424461365
Iteration 3100, loss=0.709298849105835
Iteration 3200, loss=0.6602586507797241
Iteration 3300, loss=0.6801648139953613
Iteration 3400, loss=0.6473581790924072
Iteration 3500, loss=0.7256443500518799
Iteration 3600, loss=0.7128653526306152
Iteration 3700, loss=0.7189871072769165
Iteration 3800, loss=0.6790398359298706
Iteration 3900, loss=0.683971643447876
Iteration 4000, loss=0.6760379076004028
Iteration 4100, loss=0.7035145163536072
Iteration 4200, loss=0.6901122331619263
Iteration 4300, loss=0.7002379298210144
Iteration 4400, loss=0.7079629898071289
Iteration 4500, loss=0.7165446877479553
Iteration 4600, loss=0.7154724597930908
Iteration 4700, loss=0.6930873394012451
Iteration 4800, loss=0.7102675437927246
Iteration 4900, loss=0.6973719000816345
Iteration 5000, loss=0.6928620934486389
Iteration 5100, loss=0.6993914842605591
Iteration 5200, loss=0.7022016644477844
Iteration 5300, loss=0.682548999786377
Iteration 5400, loss=0.7081869840621948
Iteration 5500, loss=0.7072461247444153
Iteration 5600, loss=0.6928728222846985
Iteration 5700, loss=0.7125274538993835
Iteration 5800, loss=0.6713051199913025
Iteration 5900, loss=0.6697670817375183
Iteration 6000, loss=0.6988785266876221
Iteration 6100, loss=0.744598925113678
Iteration 6200, loss=0.6878092288970947
Iteration 6300, loss=0.6713511943817139
Iteration 6400, loss=0.729487419128418
Iteration 6500, loss=0.7090581655502319
Iteration 6600, loss=0.6870509386062622
Iteration 6700, loss=0.7135868668556213
Iteration 6800, loss=0.6883972883224487
Iteration 6900, loss=0.7047972679138184
Iteration 7000, loss=0.6780003905296326
Iteration 7100, loss=0.7136678695678711
Iteration 7200, loss=0.6780624389648438
Iteration 7300, loss=0.7038310766220093
Iteration 7400, loss=0.6848270297050476
Iteration 7500, loss=0.6222782135009766
Iteration 7600, loss=0.705209493637085
Iteration 7700, loss=0.7058892250061035
Iteration 7800, loss=0.6964098811149597
Iteration 7900, loss=0.677553653717041
Iteration 8000, loss=0.7280961871147156
Iteration 8100, loss=0.7166293859481812
Iteration 8200, loss=0.6892474889755249
Iteration 8300, loss=0.708926260471344
Iteration 8400, loss=0.6939259171485901
Iteration 8500, loss=0.686343789100647
Iteration 8600, loss=0.6612047553062439
Iteration 8700, loss=0.713738203048706
Iteration 8800, loss=0.6832613945007324
Iteration 8900, loss=0.6964433193206787
Iteration 9000, loss=0.7208389043807983
Iteration 9100, loss=0.7052950263023376
Iteration 9200, loss=0.7091195583343506
Iteration 9300, loss=0.6911789178848267
Iteration 9400, loss=0.6183799505233765
Iteration 9500, loss=0.6685416102409363
Iteration 9600, loss=0.7020887136459351
Iteration 9700, loss=0.7060277462005615
Iteration 9800, loss=0.6447862982749939
Iteration 9900, loss=0.6632750034332275
Iteration 10000, loss=0.6749191284179688
Nearest to that: ill-service, orders, client's, you, had, faster, doughy, it,
Nearest to the: 
, ", doughy, of, to, galvanized, above, narrative,
Nearest to my: overfed, lintel, socks, existence, headkeepers, selections, lord, releasing,
Nearest to before: weeks, i, accessible, franz, pigments, eighteen, how, fish's,
Nearest to !: ", dictates, unwell, announced, inquire, ill-health, men, petulance,
Nearest to if: can, toy, 
, citadel, shadowy, free-will, men, compasses,
Nearest to could: memoirs, make, swear, somomy, sllent, tasted, somnolence, close,
Nearest to .: you, am, son, pig, this, whatever, watson, who,
Nearest to over: depose, awe, resentment, flame-like, hypnotism, cliff, concocted, divan,
Nearest to what: sixty-odd, hooked, procedure, gliding, case, eccentricities, breast-high, radiations,
Nearest to when: desperately, parisian, use, latter, motion, practice, fry, shiprecked,
Nearest to time: we, homicidal, lookout, foxy, stout-built, oysters, hinged, alliance,
Nearest to ?: loiterers, cater, calmer, reasoned, clapham, toolhouse, ", occurs,
Nearest to up: raced, enacted, observes, castles, intermediary, 88, epidemic, bowery,
Nearest to am: ., contortion, unfolding, velvet, aunt, culverton, dreams, asking,
Nearest to but: waterford, bennett's, fossil, comin, sorts, handbook, courting, shuttered,
Iteration 10100, loss=0.647486686706543
Iteration 10200, loss=0.6794261932373047
Iteration 10300, loss=0.6882328391075134
Iteration 10400, loss=0.6693336367607117
Iteration 10500, loss=0.6955110430717468
Iteration 10600, loss=0.6789261102676392
Iteration 10700, loss=0.7195609211921692
Iteration 10800, loss=0.6990303993225098
Iteration 10900, loss=0.676690936088562
Iteration 11000, loss=0.6968897581100464
Iteration 11100, loss=0.7130601406097412
Iteration 11200, loss=0.663283109664917
Iteration 11300, loss=0.6503876447677612
Iteration 11400, loss=0.6374109983444214
Iteration 11500, loss=0.6956002712249756
Iteration 11600, loss=0.6754811406135559
Iteration 11700, loss=0.6581214666366577
Iteration 11800, loss=0.7141150236129761
Iteration 11900, loss=0.6910874247550964
Iteration 12000, loss=0.644156813621521
Iteration 12100, loss=0.7447415590286255
Iteration 12200, loss=0.6626534461975098
Iteration 12300, loss=0.7137248516082764
Iteration 12400, loss=0.7116198539733887
Iteration 12500, loss=0.738150954246521
Iteration 12600, loss=0.6662909984588623
Iteration 12700, loss=0.7539946436882019
Iteration 12800, loss=0.7002046704292297
Iteration 12900, loss=0.7426765561103821
Iteration 13000, loss=0.4987426698207855
Iteration 13100, loss=0.6799508929252625
Iteration 13200, loss=0.6722314357757568
Iteration 13300, loss=0.7093502283096313
Iteration 13400, loss=0.6708769202232361
Iteration 13500, loss=0.6765111088752747
Iteration 13600, loss=0.6338515877723694
Iteration 13700, loss=0.7461762428283691
Iteration 13800, loss=0.6376718282699585
Iteration 13900, loss=0.7393386960029602
Iteration 14000, loss=0.7193175554275513
Iteration 14100, loss=0.6595383882522583
Iteration 14200, loss=0.6660084128379822
Iteration 14300, loss=0.7523320317268372
Iteration 14400, loss=0.6647731065750122
Iteration 14500, loss=0.7027921676635742
Iteration 14600, loss=0.6694483160972595
Iteration 14700, loss=0.6363787651062012
Iteration 14800, loss=0.6105726361274719
Iteration 14900, loss=0.647502064704895
Iteration 15000, loss=0.6834601163864136
Iteration 15100, loss=0.6831709742546082
Iteration 15200, loss=0.685131311416626
Iteration 15300, loss=0.7062242031097412
Iteration 15400, loss=0.6854878664016724
Iteration 15500, loss=0.7011095285415649
Iteration 15600, loss=0.7700991630554199
Iteration 15700, loss=0.6293057799339294
Iteration 15800, loss=0.6904451251029968
Iteration 15900, loss=0.6887336373329163
Iteration 16000, loss=0.7271375060081482
Iteration 16100, loss=0.6453230381011963
Iteration 16200, loss=0.7142879366874695
Iteration 16300, loss=0.6891658902168274
Iteration 16400, loss=0.6849071383476257
Iteration 16500, loss=0.7012810111045837
Iteration 16600, loss=0.6872809529304504
Iteration 16700, loss=0.7014576196670532
Iteration 16800, loss=0.7325436472892761
Iteration 16900, loss=0.7304657697677612
Iteration 17000, loss=0.6803874373435974
Iteration 17100, loss=0.6854509711265564
Iteration 17200, loss=0.646966278553009
Iteration 17300, loss=0.7020713686943054
Iteration 17400, loss=0.6769442558288574
Iteration 17500, loss=0.6567073464393616
Iteration 17600, loss=0.15412485599517822
Iteration 17700, loss=0.6970608234405518
Iteration 17800, loss=0.6883427500724792
Iteration 17900, loss=0.6753909587860107
Iteration 18000, loss=0.7320249080657959
Iteration 18100, loss=0.6830955743789673
Iteration 18200, loss=0.7093825936317444
Iteration 18300, loss=0.6696000099182129
Iteration 18400, loss=0.7100126147270203
Iteration 18500, loss=0.6856293082237244
Iteration 18600, loss=0.7011240720748901
Iteration 18700, loss=0.6908079385757446
Iteration 18800, loss=0.6346443295478821
Iteration 18900, loss=0.7453134059906006
Iteration 19000, loss=0.7332199215888977
Iteration 19100, loss=0.7179426550865173
Iteration 19200, loss=0.7100229859352112
Iteration 19300, loss=0.7589001059532166
Iteration 19400, loss=0.726073145866394
Iteration 19500, loss=0.7088704705238342
Iteration 19600, loss=0.8074617385864258
Iteration 19700, loss=0.706497073173523
Iteration 19800, loss=0.7633960247039795
Iteration 19900, loss=0.6826566457748413
Iteration 20000, loss=0.6296430230140686
Nearest to that: our, ., ", did, you, light, understand, aware,
Nearest to the: ., ,, of, to, ", when, 
, on,
Nearest to my: july, ., farrington, run, holiness, his, gloomy, constabulary,
Nearest to before: to, we, zero-point, -can't, eighteen, commenced, accessible, pigments,
Nearest to !: done, cried, ., dictates, ",  , inquire, our,
Nearest to if: lounged, and, becomes, can, 
, possibilities, you, might,
Nearest to could: lay, help, shadows, lenient, staid, memoirs, hankey's, i'd,
Nearest to .: the, he, holmes, was, our, ", you, ,,
Nearest to over: dissecting-rooms, depose, awe, shock, rescued, rearranging, uncarpeted, reverts,
Nearest to what: do, coroner, hooked, aggravated, flattering, staunton, inquire, courage,
Nearest to when: on, the, ramifications, of, aged, room, parisian, ,,
Nearest to time: may, scrutinized, stout-built, dislike, lookout, alliance, fungi, red-bearded,
Nearest to ?:  , ", i, heavy-bowed, at, ., siesta, unhealthy,
Nearest to up: bowery, wicker-work, mild-mannered, until, rattle, cunninghams, ocean, 117,
Nearest to am: irritable, garments, staggering, 6, uncovering, wicker-work, to, assert,
Nearest to but: capable, tried, bolted, interjected, that, reproached, wondered, courting,
Iteration 20100, loss=0.6919971108436584
Iteration 20200, loss=0.48159292340278625
Iteration 20300, loss=0.6322440505027771
Iteration 20400, loss=0.7139526009559631
Iteration 20500, loss=0.7090104818344116
Iteration 20600, loss=0.6623278260231018
Iteration 20700, loss=0.7148500680923462
Iteration 20800, loss=0.7026098370552063
Iteration 20900, loss=0.6679236888885498
Iteration 21000, loss=0.6919515132904053
Iteration 21100, loss=0.6514407396316528
Iteration 21200, loss=0.7533061504364014
Iteration 21300, loss=0.6952788829803467
Iteration 21400, loss=0.635579526424408
Iteration 21500, loss=0.7910730242729187
Iteration 21600, loss=0.7199357748031616
Iteration 21700, loss=0.7170644998550415
Iteration 21800, loss=0.6554286479949951
Iteration 21900, loss=0.7144907712936401
Iteration 22000, loss=0.7219368815422058
Iteration 22100, loss=0.664160430431366
Iteration 22200, loss=0.7906762361526489
Iteration 22300, loss=0.644821047782898
Iteration 22400, loss=0.6856730580329895
Iteration 22500, loss=0.7142496705055237
Iteration 22600, loss=0.5794652700424194
Iteration 22700, loss=0.642529308795929
Iteration 22800, loss=0.45810920000076294
Iteration 22900, loss=0.7145156264305115
Iteration 23000, loss=0.6915183067321777
Iteration 23100, loss=0.708852231502533
Iteration 23200, loss=0.6807312965393066
Iteration 23300, loss=0.64670729637146
Iteration 23400, loss=0.42520570755004883
Iteration 23500, loss=0.629224419593811
Iteration 23600, loss=0.6609847545623779
Iteration 23700, loss=0.6738796234130859
Iteration 23800, loss=0.803595244884491
Iteration 23900, loss=0.7049306631088257
Iteration 24000, loss=0.6454137563705444
Iteration 24100, loss=0.7143837213516235
Iteration 24200, loss=0.5561425089836121
Iteration 24300, loss=0.6895670294761658
Iteration 24400, loss=0.7179629802703857
Iteration 24500, loss=0.6843211054801941
Iteration 24600, loss=0.7123628854751587
Iteration 24700, loss=0.6899054050445557
Iteration 24800, loss=0.6815307140350342
Iteration 24900, loss=0.27099013328552246
Iteration 25000, loss=0.7355502843856812
Iteration 25100, loss=0.6747786402702332
Iteration 25200, loss=0.6815995573997498
Iteration 25300, loss=0.5728545188903809
Iteration 25400, loss=0.7341820001602173
Iteration 25500, loss=0.6389245390892029
Iteration 25600, loss=0.6912919878959656
Iteration 25700, loss=0.7233399748802185
Iteration 25800, loss=0.9266890287399292
Iteration 25900, loss=0.6592189073562622
Iteration 26000, loss=0.6768907904624939
Iteration 26100, loss=0.8001765608787537
Iteration 26200, loss=0.4642632305622101
Iteration 26300, loss=0.657835841178894
Iteration 26400, loss=0.5563095211982727
Iteration 26500, loss=0.7774807214736938
Iteration 26600, loss=0.948676586151123
Iteration 26700, loss=0.7769914269447327
Iteration 26800, loss=0.07826700806617737
Iteration 26900, loss=0.7768591642379761
Iteration 27000, loss=0.5753508806228638
Iteration 27100, loss=0.7109876871109009
Iteration 27200, loss=0.6950692534446716
Iteration 27300, loss=0.6253025531768799
Iteration 27400, loss=0.6796009540557861
Iteration 27500, loss=0.6724225878715515
Iteration 27600, loss=0.649660587310791
Iteration 27700, loss=0.7691832184791565
Iteration 27800, loss=0.7263516783714294
Iteration 27900, loss=0.4288967251777649
Iteration 28000, loss=0.6672396063804626
Iteration 28100, loss=0.7616353631019592
Iteration 28200, loss=0.6019171476364136
Iteration 28300, loss=0.7017159461975098
Iteration 28400, loss=0.6416303515434265
Iteration 28500, loss=0.6407597064971924
Iteration 28600, loss=0.6118418574333191
Iteration 28700, loss=0.3550014793872833
Iteration 28800, loss=0.5516346096992493
Iteration 28900, loss=0.3741461932659149
Iteration 29000, loss=0.5737796425819397
Iteration 29100, loss=0.6936570405960083
Iteration 29200, loss=0.6486442685127258
Iteration 29300, loss=0.6216384172439575
Iteration 29400, loss=0.3845839202404022
Iteration 29500, loss=0.6506563425064087
Iteration 29600, loss=0.6817967891693115
Iteration 29700, loss=0.6412307024002075
Iteration 29800, loss=0.644294261932373
Iteration 29900, loss=0.750492513179779
Iteration 30000, loss=0.7707687020301819
Nearest to that: our, ,, ., i, the, of, at, holmes,
Nearest to the: ,, of, when, on, this, ., no, to,
Nearest to my: you, ,, ., it, survive, one, and, he,
Nearest to before: already, ., and, commenced, we, had, pane, accessible,
Nearest to !: cried, what, ., 
, ",  , said, to,
Nearest to if: you, can, to, ", me, 
, i, and,
Nearest to could: ,, and, an, not, as, a, imagine, we,
Nearest to .: to, it, he, you, holmes, well, the, would,
Nearest to over: price, mycroft, touch, intrusive, depose, officials, flame-like, suppose,
Nearest to what: ", !, do,  , once, rage, as, not,
Nearest to when: the, ,, of, on, it, there, door, was,
Nearest to time: may, dislike, scrutinized, wasted, shady, alliance, instruments, gol-,
Nearest to ?: ",  , 
, ,, holmes, the, of, i,
Nearest to up: wicker-work, until, continent, bowery, front, raced, carpet-bags, crumpled,
Nearest to am: ., to, holmes, ,, it, be, of, and,
Nearest to but: ., that,  , this, holmes, ,, see, was,
Iteration 30100, loss=0.8027599453926086
Iteration 30200, loss=0.0019459568429738283
Iteration 30300, loss=0.72978276014328
Iteration 30400, loss=0.004258627071976662
Iteration 30500, loss=0.5694355368614197
Iteration 30600, loss=1.1121389865875244
Iteration 30700, loss=0.5869192481040955
Iteration 30800, loss=0.5914756655693054
Iteration 30900, loss=0.6256507039070129
Iteration 31000, loss=0.7157878279685974
Iteration 31100, loss=0.679829478263855
Iteration 31200, loss=0.6955544352531433
Iteration 31300, loss=0.7010076642036438
Iteration 31400, loss=1.192093321833454e-07
Iteration 31500, loss=0.7765907049179077
Iteration 31600, loss=0.7380334734916687
Iteration 31700, loss=0.675814688205719
Iteration 31800, loss=1.192093321833454e-07
Iteration 31900, loss=1.0685635805130005
Iteration 32000, loss=0.3637131452560425
Iteration 32100, loss=0.5317161083221436
Iteration 32200, loss=0.6746606230735779
Iteration 32300, loss=0.6780576705932617
Iteration 32400, loss=0.8092919588088989
Iteration 32500, loss=0.8044243454933167
Iteration 32600, loss=0.6817955374717712
Iteration 32700, loss=0.7354533672332764
Iteration 32800, loss=1.4305118156698882e-06
Iteration 32900, loss=0.6398794651031494
Iteration 33000, loss=0.6200142502784729
Iteration 33100, loss=0.6713679432868958
Iteration 33200, loss=0.8056909441947937
Iteration 33300, loss=0.4652806520462036
Iteration 33400, loss=0.6453688144683838
Iteration 33500, loss=1.2770591974258423
Iteration 33600, loss=0.54542475938797
Iteration 33700, loss=0.6734726428985596
Iteration 33800, loss=0.6598075032234192
Iteration 33900, loss=0.7264258861541748
Iteration 34000, loss=0.248450368642807
Iteration 34100, loss=0.8306946754455566
Iteration 34200, loss=0.7899907231330872
Iteration 34300, loss=0.556691586971283
Iteration 34400, loss=0.5621330142021179
Iteration 34500, loss=0.5818301439285278
Iteration 34600, loss=0.8050948977470398
Iteration 34700, loss=0.5781145095825195
Iteration 34800, loss=0.6223136782646179
Iteration 34900, loss=0.5930674076080322
Iteration 35000, loss=0.6701722145080566
Iteration 35100, loss=0.5626350045204163
Iteration 35200, loss=0.8314215540885925
Iteration 35300, loss=0.7608081102371216
Iteration 35400, loss=0.5846927762031555
Iteration 35500, loss=0.8528780937194824
Iteration 35600, loss=0.6188935041427612
Iteration 35700, loss=0.6575578451156616
Iteration 35800, loss=0.23882004618644714
Iteration 35900, loss=0.4758625030517578
Iteration 36000, loss=0.3118963837623596
Iteration 36100, loss=0.6003722548484802
Iteration 36200, loss=0.5768755078315735
Iteration 36300, loss=0.5667659640312195
Iteration 36400, loss=0.9896295070648193
Iteration 36500, loss=0.5109191536903381
Iteration 36600, loss=0.8231683969497681
Iteration 36700, loss=0.6334829330444336
Iteration 36800, loss=0.604712188243866
Iteration 36900, loss=0.8112173080444336
Iteration 37000, loss=0.005323668476194143
Iteration 37100, loss=0.6110853552818298
Iteration 37200, loss=0.54605633020401
Iteration 37300, loss=0.5124225616455078
Iteration 37400, loss=0.904869794845581
Iteration 37500, loss=0.7689142227172852
Iteration 37600, loss=0.6234200596809387
Iteration 37700, loss=0.841927707195282
Iteration 37800, loss=0.09135987609624863
Iteration 37900, loss=0.578494668006897
Iteration 38000, loss=0.5939167141914368
Iteration 38100, loss=0.6267231702804565
Iteration 38200, loss=0.8207439184188843
Iteration 38300, loss=0.5509291291236877
Iteration 38400, loss=0.5154750943183899
Iteration 38500, loss=0.5871421098709106
Iteration 38600, loss=0.562288224697113
Iteration 38700, loss=0.6298393607139587
Iteration 38800, loss=0.6082063913345337
Iteration 38900, loss=0.2818850874900818
Iteration 39000, loss=0.7142350077629089
Iteration 39100, loss=0.5473737120628357
Iteration 39200, loss=0.6604095697402954
Iteration 39300, loss=0.5647715330123901
Iteration 39400, loss=0.8417733907699585
Iteration 39500, loss=0.5395753383636475
Iteration 39600, loss=0.87306809425354
Iteration 39700, loss=0.01795070804655552
Iteration 39800, loss=0.6131216883659363
Iteration 39900, loss=0.789969801902771
Iteration 40000, loss=0.5920532941818237
Nearest to that: ,, i, was, the, out, to, ., me,
Nearest to the: ,, ., to, at, me, you, of, out,
Nearest to my: and, in, one, you, to, this, ., the,
Nearest to before: we, and, ., think, appear, norah, to, ",
Nearest to !: cried, ", 
, what, said, this,  , not,
Nearest to if: can, me, not, he, the, ?,  , i,
Nearest to could: and, make, ?, as, ,, help, not, you,
Nearest to .: to, and, the, was, me, it, he, you,
Nearest to over: shirt-sleeve, depose, price, uncarpeted, but, string, lifting, awe,
Nearest to what: ", do,  , ., to, me, !, other,
Nearest to when: it, the, ,, out, me, is, on, at,
Nearest to time: at, to, who, may, nonentity, lookout, us, 97,
Nearest to ?: ", the,  , his, no, holmes, i, this,
Nearest to up: think, go, on, front, holmes, the, he, him,
Nearest to am: it, ., for, me, to, never, a, you,
Nearest to but:  , that, ., 
, the, this, was, ",
Iteration 40100, loss=0.8039114475250244
Iteration 40200, loss=0.890168309211731
Iteration 40300, loss=0.39408108592033386
Iteration 40400, loss=0.6952575445175171
Iteration 40500, loss=8.702311788510997e-06
Iteration 40600, loss=0.7419231534004211
Iteration 40700, loss=0.5800354480743408
Iteration 40800, loss=0.9835348129272461
Iteration 40900, loss=0.6281454563140869
Iteration 41000, loss=0.5923141241073608
Iteration 41100, loss=0.5561729073524475
Iteration 41200, loss=0.6048465967178345
Iteration 41300, loss=0.6602795124053955
Iteration 41400, loss=0.8432914018630981
Iteration 41500, loss=0.42998841404914856
Iteration 41600, loss=0.0011144529562443495
Iteration 41700, loss=0.8312523365020752
Iteration 41800, loss=0.5572898387908936
Iteration 41900, loss=0.5683420896530151
Iteration 42000, loss=0.8400416374206543
Iteration 42100, loss=0.8821219205856323
Iteration 42200, loss=0.5477953553199768
Iteration 42300, loss=0.6370313167572021
Iteration 42400, loss=0.5635208487510681
Iteration 42500, loss=0.4652042090892792
Iteration 42600, loss=0.573606014251709
Iteration 42700, loss=0.7744601964950562
Iteration 42800, loss=0.433391809463501
Iteration 42900, loss=0.569979190826416
Iteration 43000, loss=0.48999544978141785
Iteration 43100, loss=0.5065602660179138
Iteration 43200, loss=0.8751624822616577
Iteration 43300, loss=0.5927612781524658
Iteration 43400, loss=0.8239290118217468
Iteration 43500, loss=0.5138784050941467
Iteration 43600, loss=0.5981358289718628
Iteration 43700, loss=0.552975594997406
Iteration 43800, loss=0.44222506880760193
Iteration 43900, loss=0.7723739147186279
Iteration 44000, loss=0.6236581206321716
Iteration 44100, loss=0.5630553364753723
Iteration 44200, loss=0.6224992871284485
Iteration 44300, loss=0.5869575142860413
Iteration 44400, loss=0.8147790431976318
Iteration 44500, loss=0.6040292978286743
Iteration 44600, loss=0.6839731335639954
Iteration 44700, loss=0.4136568605899811
Iteration 44800, loss=0.5847784876823425
Iteration 44900, loss=0.5927023887634277
Iteration 45000, loss=0.5404508709907532
Iteration 45100, loss=0.8699453473091125
Iteration 45200, loss=0.6236927509307861
Iteration 45300, loss=0.5742030143737793
Iteration 45400, loss=1.0282230377197266
Iteration 45500, loss=0.5658368468284607
Iteration 45600, loss=0.7741005420684814
Iteration 45700, loss=0.7614441514015198
Iteration 45800, loss=0.5787794589996338
Iteration 45900, loss=0.5933427214622498
Iteration 46000, loss=0.5905166268348694
Iteration 46100, loss=0.7591508030891418
Iteration 46200, loss=0.0258491113781929
Iteration 46300, loss=0.6270424127578735
Iteration 46400, loss=0.6378674507141113
Iteration 46500, loss=0.630220890045166
Iteration 46600, loss=0.9457128643989563
Iteration 46700, loss=0.5722595453262329
Iteration 46800, loss=1.2113624811172485
Iteration 46900, loss=0.6150913834571838
Iteration 47000, loss=0.49022507667541504
Iteration 47100, loss=0.6427094340324402
Iteration 47200, loss=0.7304152846336365
Iteration 47300, loss=0.4854753315448761
Iteration 47400, loss=0.535785973072052
Iteration 47500, loss=0.5646081566810608
Iteration 47600, loss=0.7012817859649658
Iteration 47700, loss=0.5846920609474182
Iteration 47800, loss=0.6019711494445801
Iteration 47900, loss=0.5020753145217896
Iteration 48000, loss=0.5476973652839661
Iteration 48100, loss=0.7005956768989563
Iteration 48200, loss=0.5885308384895325
Iteration 48300, loss=0.4862501621246338
Iteration 48400, loss=0.5439408421516418
Iteration 48500, loss=0.6048190593719482
Iteration 48600, loss=0.8414608240127563
Iteration 48700, loss=0.5498142242431641
Iteration 48800, loss=0.5885718464851379
Iteration 48900, loss=0.4871044158935547
Iteration 49000, loss=0.526929497718811
Iteration 49100, loss=0.7429484724998474
Iteration 49200, loss=0.5975131988525391
Iteration 49300, loss=0.0005920493858866394
Iteration 49400, loss=0.4870738387107849
Iteration 49500, loss=0.7251101136207581
Iteration 49600, loss=0.568037211894989
Iteration 49700, loss=0.4723297655582428
Iteration 49800, loss=0.6031478643417358
Iteration 49900, loss=0.5736611485481262
Iteration 50000, loss=0.33954259753227234
Nearest to that: ,, was, no, the, man, ., at, i,
Nearest to the: ., ,, at, to, that, have, of, no,
Nearest to my: ,, the, of, to, me, have, in, for,
Nearest to before: and, to, man, as, ., was, think, are,
Nearest to !: cried, ", she, here, this, at, what,  ,
Nearest to if: that, but, to, and, ,, was, no, will,
Nearest to could: and, a, ,, do, have, not, i, you,
Nearest to .: the, to, me, you, and, one, in, that,
Nearest to over: ., no, mr, well, ?, were, awe, see,
Nearest to what: do, ",  , holmes, and, ., ,, are,
Nearest to when: there, ,, again, out, on, the, me, it,
Nearest to time: to, for, at, ., may, have, he, was,
Nearest to ?: have, no,  , see, ,, the, ", i,
Nearest to up: on, think, the, your, him, have, holmes, a,
Nearest to am: have, to, ., i, the, it, again, you,
Nearest to but:  , that, was, if, the, this, no, said,
Iteration 50100, loss=0.7156137228012085
Iteration 50200, loss=0.7509989142417908
Iteration 50300, loss=0.6167266368865967
Iteration 50400, loss=0.5219305157661438
Iteration 50500, loss=0.1941259652376175
Iteration 50600, loss=0.5599871873855591
Iteration 50700, loss=0.9721090793609619
Iteration 50800, loss=0.5961823463439941
Iteration 50900, loss=0.8625755906105042
Iteration 51000, loss=0.528558075428009
Iteration 51100, loss=0.4959402084350586
Iteration 51200, loss=0.533177375793457
Iteration 51300, loss=0.8210775256156921
Iteration 51400, loss=0.7856916189193726
Iteration 51500, loss=0.24243757128715515
Iteration 51600, loss=1.2220773696899414
Iteration 51700, loss=0.5512011051177979
Iteration 51800, loss=0.1385190635919571
Iteration 51900, loss=0.0024054949171841145
Iteration 52000, loss=0.9362074136734009
Iteration 52100, loss=0.5668723583221436
Iteration 52200, loss=0.5881243944168091
Iteration 52300, loss=0.5816007852554321
Iteration 52400, loss=0.5526782274246216
Iteration 52500, loss=0.4999677836894989
Iteration 52600, loss=0.6463356614112854
Iteration 52700, loss=0.4898163676261902
Iteration 52800, loss=0.5318582653999329
Iteration 52900, loss=0.1595207303762436
Iteration 53000, loss=1.192093321833454e-07
Iteration 53100, loss=9.739874076331034e-05
Iteration 53200, loss=0.6052513718605042
Iteration 53300, loss=0.7995997667312622
Iteration 53400, loss=1.0477194786071777
Iteration 53500, loss=1.0132331848144531
Iteration 53600, loss=0.9481688737869263
Iteration 53700, loss=0.7827095985412598
Iteration 53800, loss=0.5343005657196045
Iteration 53900, loss=0.8887597322463989
Iteration 54000, loss=0.9979711771011353
Iteration 54100, loss=0.5015894174575806
Iteration 54200, loss=0.46907663345336914
Iteration 54300, loss=0.49035635590553284
Iteration 54400, loss=0.3606162667274475
Iteration 54500, loss=0.5345221161842346
Iteration 54600, loss=0.5023845434188843
Iteration 54700, loss=0.46450138092041016
Iteration 54800, loss=0.5397421717643738
Iteration 54900, loss=0.24352480471134186
Iteration 55000, loss=1.3458510637283325
Iteration 55100, loss=0.8143101930618286
Iteration 55200, loss=0.6391304135322571
Iteration 55300, loss=0.6059421896934509
Iteration 55400, loss=1.192093321833454e-07
Iteration 55500, loss=0.4873031675815582
Iteration 55600, loss=1.325559377670288
Iteration 55700, loss=0.01058992650359869
Iteration 55800, loss=0.576812207698822
Iteration 55900, loss=0.27562928199768066
Iteration 56000, loss=0.5328395962715149
Iteration 56100, loss=0.5227894186973572
Iteration 56200, loss=0.6153274774551392
Iteration 56300, loss=0.03763428330421448
Iteration 56400, loss=0.4154658317565918
Iteration 56500, loss=0.5730879306793213
Iteration 56600, loss=0.5088712573051453
Iteration 56700, loss=0.44955942034721375
Iteration 56800, loss=0.7380275726318359
Iteration 56900, loss=0.54145747423172
Iteration 57000, loss=0.9368340373039246
Iteration 57100, loss=0.7898717522621155
Iteration 57200, loss=0.8816465735435486
Iteration 57300, loss=0.9016416072845459
Iteration 57400, loss=0.5542348623275757
Iteration 57500, loss=0.33227232098579407
Iteration 57600, loss=0.9149475693702698
Iteration 57700, loss=0.8189183473587036
Iteration 57800, loss=0.2677308917045593
Iteration 57900, loss=0.49315401911735535
Iteration 58000, loss=0.5316120386123657
Iteration 58100, loss=0.20883974432945251
Iteration 58200, loss=0.6073842644691467
Iteration 58300, loss=0.536339521408081
Iteration 58400, loss=0.33572015166282654
Iteration 58500, loss=0.45258697867393494
Iteration 58600, loss=0.449422150850296
Iteration 58700, loss=0.9353010058403015
Iteration 58800, loss=0.6918469667434692
Iteration 58900, loss=0.5973079204559326
Iteration 59000, loss=0.27122819423675537
Iteration 59100, loss=0.5661056041717529
Iteration 59200, loss=0.13282626867294312
Iteration 59300, loss=0.40370166301727295
Iteration 59400, loss=0.2949426770210266
Iteration 59500, loss=0.4500606954097748
Iteration 59600, loss=0.7917453646659851
Iteration 59700, loss=0.01647523231804371
Iteration 59800, loss=0.45728015899658203
Iteration 59900, loss=5.96046561440744e-07
Iteration 60000, loss=0.47976580262184143
Nearest to that: ,, be, to, i, out, have, you, the,
Nearest to the: at, ,, ., no, a, again, one, when,
Nearest to my: you, in, out, ,, ., to, me, of,
Nearest to before: to, you, we, ., out, was, man, as,
Nearest to !: cried, ", ., she, 
, me, said,  ,
Nearest to if: you, i, to, not, that, but, me, no,
Nearest to could: not, and, ?, as, you, i, my, did,
Nearest to .: me, you, the, to, in, not, again, would,
Nearest to over: have, to, no, well, here, was, ,, man,
Nearest to what: ", did, are, do, you, ., said, is,
Nearest to when: the, ,, it, again, no, a, is, one,
Nearest to time: ,, at, was, a, not, man, us, for,
Nearest to ?: have,  , ', not, no, at, see, could,
Nearest to up: him, ., the, one, on, think, no, me,
Nearest to am: to, a, ., my, again, i, but, you,
Nearest to but: the, said, this, was, if, of, .,  ,
Iteration 60100, loss=0.5559446811676025
Iteration 60200, loss=0.5004682540893555
Iteration 60300, loss=0.008164506405591965
Iteration 60400, loss=0.8876231908798218
Iteration 60500, loss=0.5123074650764465
Iteration 60600, loss=0.4011397361755371
Iteration 60700, loss=0.006015655118972063
Iteration 60800, loss=0.003532383358106017
Iteration 60900, loss=0.5200974941253662
Iteration 61000, loss=0.6303634643554688
Iteration 61100, loss=0.47162914276123047
Iteration 61200, loss=2.0568978786468506
Iteration 61300, loss=0.5938610434532166
Iteration 61400, loss=0.4637661576271057
Iteration 61500, loss=0.6278980374336243
Iteration 61600, loss=1.0962010622024536
Iteration 61700, loss=0.45919492840766907
Iteration 61800, loss=0.5464630722999573
Iteration 61900, loss=0.0014834078028798103
Iteration 62000, loss=0.5653449892997742
Iteration 62100, loss=0.017819887027144432
Iteration 62200, loss=0.5023170709609985
Iteration 62300, loss=0.621112048625946
Iteration 62400, loss=0.4650131165981293
Iteration 62500, loss=0.9753884077072144
Iteration 62600, loss=0.1846940964460373
Iteration 62700, loss=0.9037366509437561
Iteration 62800, loss=1.062940001487732
Iteration 62900, loss=0.5488848090171814
Iteration 63000, loss=0.22351010143756866
Iteration 63100, loss=1.192093321833454e-07
Iteration 63200, loss=0.4250510632991791
Iteration 63300, loss=0.18386435508728027
Iteration 63400, loss=0.7441691756248474
Iteration 63500, loss=0.5005050897598267
Iteration 63600, loss=0.676626443862915
Iteration 63700, loss=0.49028313159942627
Iteration 63800, loss=0.5277077555656433
Iteration 63900, loss=0.43093571066856384
Iteration 64000, loss=3.4021012783050537
Iteration 64100, loss=0.5411102771759033
Iteration 64200, loss=0.4574916362762451
Iteration 64300, loss=0.5988999009132385
Iteration 64400, loss=0.4140426814556122
Iteration 64500, loss=0.8838434219360352
Iteration 64600, loss=0.010569320991635323
Iteration 64700, loss=0.8748237490653992
Iteration 64800, loss=0.013477863743901253
Iteration 64900, loss=0.5241066217422485
Iteration 65000, loss=0.48165783286094666
Iteration 65100, loss=0.003614692250266671
Iteration 65200, loss=1.6434247493743896
Iteration 65300, loss=1.76776921749115
Iteration 65400, loss=0.529654324054718
Iteration 65500, loss=0.391933411359787
Iteration 65600, loss=0.0023249571677297354
Iteration 65700, loss=0.6120660901069641
Iteration 65800, loss=0.7940582633018494
Iteration 65900, loss=1.9310730695724487
Iteration 66000, loss=0.4122302234172821
Iteration 66100, loss=0.055993277579545975
Iteration 66200, loss=0.3856567442417145
Iteration 66300, loss=0.4023284316062927
Iteration 66400, loss=1.0754177570343018
Iteration 66500, loss=1.0965211391448975
Iteration 66600, loss=0.2544211149215698
Iteration 66700, loss=0.496891587972641
Iteration 66800, loss=1.091135859489441
Iteration 66900, loss=0.33662149310112
Iteration 67000, loss=0.006933530326932669
Iteration 67100, loss=0.412990927696228
Iteration 67200, loss=0.07461187988519669
Iteration 67300, loss=0.5155361294746399
Iteration 67400, loss=0.30607879161834717
Iteration 67500, loss=0.46910908818244934
Iteration 67600, loss=0.43235647678375244
Iteration 67700, loss=1.0264978408813477
Iteration 67800, loss=0.7197955250740051
Iteration 67900, loss=0.013553624972701073
Iteration 68000, loss=0.42297378182411194
Iteration 68100, loss=0.4565459191799164
Iteration 68200, loss=1.0654195547103882
Iteration 68300, loss=0.7217330932617188
Iteration 68400, loss=0.9216208457946777
Iteration 68500, loss=0.2797444760799408
Iteration 68600, loss=0.25595927238464355
Iteration 68700, loss=0.44343581795692444
Iteration 68800, loss=0.0705229640007019
Iteration 68900, loss=0.6200916171073914
Iteration 69000, loss=0.47790616750717163
Iteration 69100, loss=1.5497212189075071e-06
Iteration 69200, loss=0.44656702876091003
Iteration 69300, loss=1.2847118377685547
Iteration 69400, loss=0.4328485131263733
Iteration 69500, loss=0.9079283475875854
Iteration 69600, loss=0.4587511122226715
Iteration 69700, loss=0.3385128974914551
Iteration 69800, loss=0.4725490212440491
Iteration 69900, loss=0.818903386592865
Iteration 70000, loss=0.4281371533870697
Nearest to that: to, was, ,, no, you, out, be, not,
Nearest to the: ,, at, no, one, ?, in, ., when,
Nearest to my: ,, one, you, and, me, could, ., he,
Nearest to before: to, out, we, one, man, ., was, you,
Nearest to !: cried, ",  , ., at, done, think, you,
Nearest to if: you, i, to, not, he, the, that, me,
Nearest to could: not, my, and, you, ?, ,, man, are,
Nearest to .: me, one, he, was, to, and, you, have,
Nearest to over: were, have, he, ,, was, ., to, did,
Nearest to what: ", ., do, are, ?, said, me, us,
Nearest to when: the, him, one, it, again, was, ., no,
Nearest to time: we, all, at, for, was, not, us, ,,
Nearest to ?: at,  , the, you, was, no, watson, said,
Nearest to up: him, ., me, in, think, again, our, the,
Nearest to am: ., i, a, my, one, if, watson, he,
Nearest to but: the, that, out, ., in, ,, one, he,
Iteration 70100, loss=0.3935993015766144
Iteration 70200, loss=0.522773265838623
Iteration 70300, loss=0.7613056898117065
Iteration 70400, loss=0.006264118477702141
Iteration 70500, loss=0.5564263463020325
Iteration 70600, loss=0.38215261697769165
Iteration 70700, loss=0.39822232723236084
Iteration 70800, loss=0.9840834140777588
Iteration 70900, loss=0.485760897397995
Iteration 71000, loss=0.4104156494140625
Iteration 71100, loss=0.9007003307342529
Iteration 71200, loss=0.6492788791656494
Iteration 71300, loss=0.0011379038915038109
Iteration 71400, loss=0.8208740949630737
Iteration 71500, loss=0.4320888817310333
Iteration 71600, loss=0.3961569666862488
Iteration 71700, loss=0.6545750498771667
Iteration 71800, loss=0.4894637167453766
Iteration 71900, loss=0.0001943897077580914
Iteration 72000, loss=0.9803473949432373
Iteration 72100, loss=0.41279447078704834
Iteration 72200, loss=0.9326479434967041
Iteration 72300, loss=0.08536963164806366
Iteration 72400, loss=0.45749151706695557
Iteration 72500, loss=0.3166884481906891
Iteration 72600, loss=0.36936330795288086
Iteration 72700, loss=0.46504881978034973
Iteration 72800, loss=0.14900022745132446
Iteration 72900, loss=0.481157511472702
Iteration 73000, loss=0.3777977228164673
Iteration 73100, loss=0.627814531326294
Iteration 73200, loss=0.44077005982398987
Iteration 73300, loss=1.192093321833454e-07
Iteration 73400, loss=0.31648167967796326
Iteration 73500, loss=0.527106523513794
Iteration 73600, loss=0.3223899304866791
Iteration 73700, loss=1.129715919494629
Iteration 73800, loss=0.3683657646179199
Iteration 73900, loss=0.28418198227882385
Iteration 74000, loss=0.33983710408210754
Iteration 74100, loss=0.7101022005081177
Iteration 74200, loss=1.034685730934143
Iteration 74300, loss=0.32607704401016235
Iteration 74400, loss=1.1701273918151855
Iteration 74500, loss=0.006842846050858498
Iteration 74600, loss=0.3793586194515228
Iteration 74700, loss=1.4449288845062256
Iteration 74800, loss=0.7991319894790649
Iteration 74900, loss=0.4090013802051544
Iteration 75000, loss=0.34147030115127563
Iteration 75100, loss=0.46073487401008606
Iteration 75200, loss=0.9164159893989563
Iteration 75300, loss=0.5134779214859009
Iteration 75400, loss=0.3807746469974518
Iteration 75500, loss=0.11600729823112488
Iteration 75600, loss=0.331580251455307
Iteration 75700, loss=0.5622591376304626
Iteration 75800, loss=1.192093321833454e-07
Iteration 75900, loss=2.980237695737742e-06
Iteration 76000, loss=1.981938123703003
Iteration 76100, loss=0.48038449883461
Iteration 76200, loss=0.4098791778087616
Iteration 76300, loss=0.18062502145767212
Iteration 76400, loss=1.060306429862976
Iteration 76500, loss=0.48283642530441284
Iteration 76600, loss=1.192093321833454e-07
Iteration 76700, loss=0.37384241819381714
Iteration 76800, loss=0.48874807357788086
Iteration 76900, loss=0.4321066439151764
Iteration 77000, loss=0.6148706674575806
Iteration 77100, loss=0.3337532877922058
Iteration 77200, loss=0.20903858542442322
Iteration 77300, loss=0.37791869044303894
Iteration 77400, loss=0.03677938133478165
Iteration 77500, loss=0.20801767706871033
Iteration 77600, loss=0.03369085118174553
Iteration 77700, loss=0.8862925171852112
Iteration 77800, loss=0.36462467908859253
Iteration 77900, loss=1.192093321833454e-07
Iteration 78000, loss=0.28963664174079895
Iteration 78100, loss=0.6868607997894287
Iteration 78200, loss=1.0136443376541138
Iteration 78300, loss=0.3827347755432129
Iteration 78400, loss=0.5448817014694214
Iteration 78500, loss=1.1323601007461548
Iteration 78600, loss=0.4990476369857788
Iteration 78700, loss=1.7071248292922974
Iteration 78800, loss=0.0039861262775957584
Iteration 78900, loss=0.3991222381591797
Iteration 79000, loss=0.8504595756530762
Iteration 79100, loss=0.33184701204299927
Iteration 79200, loss=0.18692173063755035
Iteration 79300, loss=0.5802062749862671
Iteration 79400, loss=0.004420140292495489
Iteration 79500, loss=1.0933829545974731
Iteration 79600, loss=0.030133919790387154
Iteration 79700, loss=1.192093321833454e-07
Iteration 79800, loss=0.4844820499420166
Iteration 79900, loss=0.49299517273902893
Iteration 80000, loss=0.8261032104492188
Nearest to that: i, were, one, be, was, out, no, will,
Nearest to the: no, there, at, ,, ., a, in, we,
Nearest to my: you, could, and, one, see, ,, we, has,
Nearest to before: out, to, ., man, we, was, that, by,
Nearest to !: cried, this, we, ", ?, before, me, at,
Nearest to if: you, not, will, ?, i, no, were, me,
Nearest to could: ?, not, you, my, see, i, we, have,
Nearest to .: me, now, the, have, as, there, here, not,
Nearest to over: there, were, no, that, man, the, to, i,
Nearest to what: ", me, said, you, ?, ., are, see,
Nearest to when: as, no, it, ., the, is, there, me,
Nearest to time: at, not, we, to, would, in, ., now,
Nearest to ?: could, only, was, be, no, at, that, one,
Nearest to up: him, on, go, ., he, again, one, remarked,
Nearest to am: my, ., i, no, as, to, me, watson,
Nearest to but: watson, that, very,  , ., the, was, see,
Iteration 80100, loss=0.0007046558894217014
Iteration 80200, loss=0.4725002348423004
Iteration 80300, loss=0.7515963912010193
Iteration 80400, loss=1.1560673713684082
Iteration 80500, loss=0.189603790640831
Iteration 80600, loss=0.3421376049518585
Iteration 80700, loss=0.3683066666126251
Iteration 80800, loss=1.3867918252944946
Iteration 80900, loss=1.192093321833454e-07
Iteration 81000, loss=0.4667258858680725
Iteration 81100, loss=0.4149894416332245
Iteration 81200, loss=0.4018727242946625
Iteration 81300, loss=0.6732774972915649
Iteration 81400, loss=0.04091844707727432
Iteration 81500, loss=0.4298592209815979
Iteration 81600, loss=0.4526292085647583
Iteration 81700, loss=0.9452987909317017
Iteration 81800, loss=0.4978067874908447
Iteration 81900, loss=0.7829316258430481
Iteration 82000, loss=0.3243716359138489
Iteration 82100, loss=1.192093321833454e-07
Iteration 82200, loss=0.0014716479927301407
Iteration 82300, loss=0.5343155264854431
Iteration 82400, loss=0.00030009474721737206
Iteration 82500, loss=0.3611430525779724
Iteration 82600, loss=0.000986347091384232
Iteration 82700, loss=0.43710699677467346
Iteration 82800, loss=0.42159608006477356
Iteration 82900, loss=0.18982933461666107
Iteration 83000, loss=0.36600539088249207
Iteration 83100, loss=0.3839412033557892
Iteration 83200, loss=0.37507495284080505
Iteration 83300, loss=1.192093321833454e-07
Iteration 83400, loss=0.48271527886390686
Iteration 83500, loss=0.6074444651603699
Iteration 83600, loss=1.1100491285324097
Iteration 83700, loss=0.420520156621933
Iteration 83800, loss=0.1238488182425499
Iteration 83900, loss=0.3380679488182068
Iteration 84000, loss=0.3947550654411316
Iteration 84100, loss=1.192093321833454e-07
Iteration 84200, loss=0.33409833908081055
Iteration 84300, loss=1.155060052871704
Iteration 84400, loss=0.5155677795410156
Iteration 84500, loss=1.192093321833454e-07
Iteration 84600, loss=0.3921234905719757
Iteration 84700, loss=1.7838528156280518
Iteration 84800, loss=1.3193111419677734
Iteration 84900, loss=0.3566621243953705
Iteration 85000, loss=0.07610436528921127
Iteration 85100, loss=0.3494367003440857
Iteration 85200, loss=0.04127735272049904
Iteration 85300, loss=0.3166872262954712
Iteration 85400, loss=3.8252182006835938
Iteration 85500, loss=0.39561203122138977
Iteration 85600, loss=0.07469621300697327
Iteration 85700, loss=0.5530471205711365
Iteration 85800, loss=0.46892717480659485
Iteration 85900, loss=0.47080832719802856
Iteration 86000, loss=1.2267999649047852
Iteration 86100, loss=0.5454548597335815
Iteration 86200, loss=0.2704237997531891
Iteration 86300, loss=0.3079942762851715
Iteration 86400, loss=0.31209003925323486
Iteration 86500, loss=0.45284637808799744
Iteration 86600, loss=0.33329859375953674
Iteration 86700, loss=0.0009103384800255299
Iteration 86800, loss=0.35430243611335754
Iteration 86900, loss=0.6030866503715515
Iteration 87000, loss=1.470926284790039
Iteration 87100, loss=0.44007161259651184
Iteration 87200, loss=0.001075309468433261
Iteration 87300, loss=1.192093321833454e-07
Iteration 87400, loss=1.192093321833454e-07
Iteration 87500, loss=1.3144185543060303
Iteration 87600, loss=1.5500450134277344
Iteration 87700, loss=0.980516791343689
Iteration 87800, loss=0.5336555242538452
Iteration 87900, loss=0.42723560333251953
Iteration 88000, loss=0.3815452754497528
Iteration 88100, loss=0.08947455883026123
Iteration 88200, loss=0.3046998977661133
Iteration 88300, loss=3.0360794067382812
Iteration 88400, loss=2.6044347286224365
Iteration 88500, loss=1.2052078247070312
Iteration 88600, loss=0.18861757218837738
Iteration 88700, loss=2.888387680053711
Iteration 88800, loss=0.13709738850593567
Iteration 88900, loss=1.192093321833454e-07
Iteration 89000, loss=1.192093321833454e-07
Iteration 89100, loss=1.192093321833454e-07
Iteration 89200, loss=1.0567126274108887
Iteration 89300, loss=0.0007838698802515864
Iteration 89400, loss=0.028508935123682022
Iteration 89500, loss=1.3012810945510864
Iteration 89600, loss=1.192093321833454e-07
Iteration 89700, loss=1.192093321833454e-07
Iteration 89800, loss=1.1863881349563599
Iteration 89900, loss=0.2770260274410248
Iteration 90000, loss=0.4326895475387573
Nearest to that: was, be, only, i, now, out, were, are,
Nearest to the: in, there, a, you, that, no, all, we,
Nearest to my: you, one, we, me, now, it, done, before,
Nearest to before: ., my, you, man, to, we, out, was,
Nearest to !: cried, ",  , what, this, 
, we, had,
Nearest to if: you, be, i, me, that, not, now, no,
Nearest to could: not, you, ?, come, tell, do, if, would,
Nearest to .: me, ", was, before, now, what, the, and,
Nearest to over: there, was, again, that, man, the, no, time,
Nearest to what: ., ", you, ?, do, have, as, me,
Nearest to when: it, as, very, the, again, now, only, at,
Nearest to time: at, not, us, would, for, to, you, my,
Nearest to ?: could, there, only, was, see, be, no, the,
Nearest to up: the, him, on, are, in, to, have, one,
Nearest to am: never, my, in, to, a, you, it, if,
Nearest to but: that, was, out, very, the, we, of, watson,
Iteration 90100, loss=1.192093321833454e-07
Iteration 90200, loss=0.16284061968326569
Iteration 90300, loss=1.192093321833454e-07
Iteration 90400, loss=0.4382978081703186
Iteration 90500, loss=1.192093321833454e-07
Iteration 90600, loss=0.4042262136936188
Iteration 90700, loss=0.5267274379730225
Iteration 90800, loss=0.45937055349349976
Iteration 90900, loss=0.36214542388916016
Iteration 91000, loss=2.9564353098976426e-05
Iteration 91100, loss=0.3513149321079254
Iteration 91200, loss=0.42535173892974854
Iteration 91300, loss=0.1916784793138504
Iteration 91400, loss=1.0641067028045654
Iteration 91500, loss=0.7175635099411011
Iteration 91600, loss=0.045842450112104416
Iteration 91700, loss=0.11709634959697723
Iteration 91800, loss=0.3378736078739166
Iteration 91900, loss=1.192093321833454e-07
Iteration 92000, loss=0.4615301787853241
Iteration 92100, loss=1.192093321833454e-07
Iteration 92200, loss=4.768372718899627e-07
Iteration 92300, loss=9.28683002712205e-05
Iteration 92400, loss=0.37292253971099854
Iteration 92500, loss=1.192093321833454e-07
Iteration 92600, loss=5.6554741859436035
Iteration 92700, loss=0.4310617744922638
Iteration 92800, loss=0.5267201066017151
Iteration 92900, loss=0.0010145683772861958
Iteration 93000, loss=1.1518261432647705
Iteration 93100, loss=0.0012329070596024394
Iteration 93200, loss=2.357649326324463
Iteration 93300, loss=1.3078303337097168
Iteration 93400, loss=0.5045424699783325
Iteration 93500, loss=1.192093321833454e-07
Iteration 93600, loss=0.4178304672241211
Iteration 93700, loss=0.3816993236541748
Iteration 93800, loss=0.0031908941455185413
Iteration 93900, loss=0.4373481273651123
Iteration 94000, loss=0.5884530544281006
Iteration 94100, loss=0.5257198810577393
Iteration 94200, loss=1.1872495412826538
Iteration 94300, loss=0.001882953685708344
Iteration 94400, loss=0.006327938754111528
Iteration 94500, loss=0.6127079129219055
Iteration 94600, loss=0.7916719913482666
Iteration 94700, loss=0.14100611209869385
Iteration 94800, loss=1.1780890226364136
Iteration 94900, loss=1.192093321833454e-07
Iteration 95000, loss=0.050203826278448105
Iteration 95100, loss=0.6095377206802368
Iteration 95200, loss=1.207784652709961
Iteration 95300, loss=1.192093321833454e-07
Iteration 95400, loss=0.015721894800662994
Iteration 95500, loss=0.408424437046051
Iteration 95600, loss=0.272076815366745
Iteration 95700, loss=0.25618818402290344
Iteration 95800, loss=0.27973175048828125
Iteration 95900, loss=0.42739421129226685
Iteration 96000, loss=0.34151771664619446
Iteration 96100, loss=0.12942059338092804
Iteration 96200, loss=0.32850632071495056
Iteration 96300, loss=1.2171001434326172
Iteration 96400, loss=0.3545798361301422
Iteration 96500, loss=0.5120252370834351
Iteration 96600, loss=0.6180471777915955
Iteration 96700, loss=0.00046776741510257125
Iteration 96800, loss=0.5538728833198547
Iteration 96900, loss=0.11792987585067749
Iteration 97000, loss=0.12823592126369476
Iteration 97100, loss=0.5402597188949585
Iteration 97200, loss=0.7698617577552795
Iteration 97300, loss=0.30729344487190247
Iteration 97400, loss=0.00027141670580022037
Iteration 97500, loss=1.0821926593780518
Iteration 97600, loss=0.31540995836257935
Iteration 97700, loss=0.9666003584861755
Iteration 97800, loss=3.075538158416748
Iteration 97900, loss=0.3552047610282898
Iteration 98000, loss=0.3316029906272888
Iteration 98100, loss=0.424295574426651
Iteration 98200, loss=0.40028974413871765
Iteration 98300, loss=0.25698262453079224
Iteration 98400, loss=0.5168274641036987
Iteration 98500, loss=0.0007186729344539344
Iteration 98600, loss=0.3988059163093567
Iteration 98700, loss=0.28613629937171936
Iteration 98800, loss=1.3616067171096802
Iteration 98900, loss=1.192093321833454e-07
Iteration 99000, loss=0.4385063350200653
Iteration 99100, loss=0.3327712118625641
Iteration 99200, loss=1.192093321833454e-07
Iteration 99300, loss=1.2730863094329834
Iteration 99400, loss=0.20126940310001373
Iteration 99500, loss=0.10843232274055481
Iteration 99600, loss=1.3440914154052734
Iteration 99700, loss=0.0004178562085144222
Iteration 99800, loss=0.24667271971702576
Iteration 99900, loss=0.3846656382083893
Iteration 100000, loss=0.36882591247558594
Nearest to that: was, the, were, you, but, no, out, if,
Nearest to the: ., in, now, ,, there, you, that, no,
Nearest to my: you, we, very, from, i, see, now, .,
Nearest to before: to, you, was, my, ., out, we, man,
Nearest to !: cried, ", my, what, me, to, before, you,
Nearest to if: you, no, to, be, that, not, was, the,
Nearest to could: you, come, not, no, from, has, very, be,
Nearest to .: me, the, was, you, that, very, in, with,
Nearest to over: to, the, that, there, was, no, were, tell,
Nearest to what: ", do, ., you, see,  , make, are,
Nearest to when: one, the, at, you, me, that, as, no,
Nearest to time: not, to, we, would, at, ,, now, that,
Nearest to ?: no, see, have, there, be, not, could, you,
Nearest to up: have, the, go, put, very, were, on, him,
Nearest to am: my, still, if, ., you, never, it, in,
Nearest to but: very, that, the, ., of, no, if, my,
Iteration 100100, loss=0.9652276039123535
Iteration 100200, loss=0.41255563497543335
Iteration 100300, loss=0.27200087904930115
Iteration 100400, loss=1.192093321833454e-07
Iteration 100500, loss=1.192093321833454e-07
Iteration 100600, loss=3.5405802918830886e-05
Iteration 100700, loss=1.6389973163604736
Iteration 100800, loss=0.49769657850265503
Iteration 100900, loss=0.31082746386528015
Iteration 101000, loss=0.9392470121383667
Iteration 101100, loss=0.345522403717041
Iteration 101200, loss=0.5766364336013794
Iteration 101300, loss=3.2186549105972517e-06
Iteration 101400, loss=0.1840658336877823
Iteration 101500, loss=0.5264852643013
Iteration 101600, loss=5.623552322387695
Iteration 101700, loss=0.3625360131263733
Iteration 101800, loss=0.3155519664287567
Iteration 101900, loss=0.5026495456695557
Iteration 102000, loss=1.4960603713989258
Iteration 102100, loss=0.6930097341537476
Iteration 102200, loss=1.6838641166687012
Iteration 102300, loss=0.35799574851989746
Iteration 102400, loss=0.3804527223110199
Iteration 102500, loss=0.567257285118103
Iteration 102600, loss=0.37056174874305725
Iteration 102700, loss=1.192093321833454e-07
Iteration 102800, loss=0.25549283623695374
Iteration 102900, loss=0.9733837842941284
Iteration 103000, loss=0.2987372577190399
Iteration 103100, loss=0.08194876462221146
Iteration 103200, loss=0.28440216183662415
Iteration 103300, loss=0.5482363104820251
Iteration 103400, loss=1.192093321833454e-07
Iteration 103500, loss=0.16582006216049194
Iteration 103600, loss=0.8348344564437866
Iteration 103700, loss=1.192093321833454e-07
Iteration 103800, loss=0.16472965478897095
Iteration 103900, loss=0.313014954328537
Iteration 104000, loss=0.4125831723213196
Iteration 104100, loss=0.3625825047492981
Iteration 104200, loss=1.6093386875581928e-05
Iteration 104300, loss=1.192093321833454e-07
Iteration 104400, loss=0.3764611780643463
Iteration 104500, loss=0.4124521017074585
Iteration 104600, loss=1.1946130990982056
Iteration 104700, loss=0.3088764548301697
Iteration 104800, loss=1.2071688175201416
Iteration 104900, loss=0.46075376868247986
Iteration 105000, loss=0.2735508382320404
Iteration 105100, loss=0.3427892327308655
Iteration 105200, loss=0.002167366212233901
Iteration 105300, loss=0.4387299418449402
Iteration 105400, loss=0.28581592440605164
Iteration 105500, loss=0.19821743667125702
Iteration 105600, loss=0.3164478540420532
Iteration 105700, loss=0.17102380096912384
Iteration 105800, loss=0.15785415470600128
Iteration 105900, loss=0.9666129946708679
Iteration 106000, loss=1.2785149812698364
Iteration 106100, loss=0.41075897216796875
Iteration 106200, loss=0.3900008499622345
Iteration 106300, loss=1.192093321833454e-07
Iteration 106400, loss=0.5397714376449585
Iteration 106500, loss=0.3887938857078552
Iteration 106600, loss=1.192093321833454e-07
Iteration 106700, loss=0.3152936100959778
Iteration 106800, loss=0.27067312598228455
Iteration 106900, loss=0.24101129174232483
Iteration 107000, loss=1.192093321833454e-07
Iteration 107100, loss=2.5033973543031607e-06
Iteration 107200, loss=1.5015521049499512
Iteration 107300, loss=1.3351526831684168e-05
Iteration 107400, loss=1.192093321833454e-07
Iteration 107500, loss=0.1394505351781845
Iteration 107600, loss=5.1260121836094186e-06
Iteration 107700, loss=0.13194426894187927
Iteration 107800, loss=0.3577594459056854
Iteration 107900, loss=0.029165668413043022
Iteration 108000, loss=0.3295098543167114
Iteration 108100, loss=0.6116288900375366
Iteration 108200, loss=2.5868752345559187e-05
Iteration 108300, loss=1.192093321833454e-07
Iteration 108400, loss=0.256841242313385
Iteration 108500, loss=0.009818858467042446
Iteration 108600, loss=0.018968719989061356
Iteration 108700, loss=0.9409103989601135
Iteration 108800, loss=0.3483482897281647
Iteration 108900, loss=0.0011542540742084384
Iteration 109000, loss=0.01904757134616375
Iteration 109100, loss=0.20230253040790558
Iteration 109200, loss=1.192093321833454e-07
Iteration 109300, loss=0.012974139302968979
Iteration 109400, loss=1.1529171466827393
Iteration 109500, loss=0.14916349947452545
Iteration 109600, loss=0.242079958319664
Iteration 109700, loss=0.18082459270954132
Iteration 109800, loss=0.0006593851139768958
Iteration 109900, loss=0.33612895011901855
Iteration 110000, loss=0.32140272855758667
Nearest to that: you, have, no, out, i, be, but, at,
Nearest to the: there, ,, in, you, ., at, him, that,
Nearest to my: you, it, we, would, as, have, i, had,
Nearest to before: ., you, but, to, my, she, been, i,
Nearest to !: ", we, cried, she, had, you, will, ?,
Nearest to if: you, our, could, no, have, watson, there, to,
Nearest to could: you, if, have, our, he, has, do, not,
Nearest to .: the, me, you, with, very, was, are, in,
Nearest to over: were, was, man, the, i, there, to, out,
Nearest to what: you, see, ", do, are, he, ?, your,
Nearest to when: have, the, only, at, you, very, there, as,
Nearest to time: would, ,, has, our, were, to, have, we,
Nearest to ?: have, you, there, he, if, only, had, me,
Nearest to up: the, have, him, on, your, remarked, me, in,
Nearest to am: to, still, glad, you, before, my, that, as,
Nearest to but: that, very, one, of, i, was, is, now,
Iteration 110100, loss=0.34634771943092346
Iteration 110200, loss=0.4007156491279602
Iteration 110300, loss=1.192093321833454e-07
Iteration 110400, loss=0.3750683069229126
Iteration 110500, loss=1.192093321833454e-07
Iteration 110600, loss=0.0008970946655608714
Iteration 110700, loss=0.18962246179580688
Iteration 110800, loss=0.28095898032188416
Iteration 110900, loss=0.34906598925590515
Iteration 111000, loss=0.47415196895599365
Iteration 111100, loss=0.4428856074810028
Iteration 111200, loss=2.3841853646899835e-07
Iteration 111300, loss=0.3947440981864929
Iteration 111400, loss=0.35404905676841736
Iteration 111500, loss=0.4439518451690674
Iteration 111600, loss=5.245220108918147e-06
Iteration 111700, loss=1.2561933994293213
Iteration 111800, loss=1.192093321833454e-07
Iteration 111900, loss=0.4500410258769989
Iteration 112000, loss=0.17676344513893127
Iteration 112100, loss=0.35436439514160156
Iteration 112200, loss=0.016996903344988823
Iteration 112300, loss=0.2597660422325134
Iteration 112400, loss=1.5213394165039062
Iteration 112500, loss=3.795795440673828
Iteration 112600, loss=0.970258355140686
Iteration 112700, loss=0.2489517331123352
Iteration 112800, loss=1.192093321833454e-07
Iteration 112900, loss=0.4103645086288452
Iteration 113000, loss=0.6689536571502686
Iteration 113100, loss=0.9553873538970947
Iteration 113200, loss=0.3097675144672394
Iteration 113300, loss=0.0008970347698777914
Iteration 113400, loss=0.10521305352449417
Iteration 113500, loss=0.6980178952217102
Iteration 113600, loss=0.3851988911628723
Iteration 113700, loss=1.192093321833454e-07
Iteration 113800, loss=0.21583600342273712
Iteration 113900, loss=0.009513726457953453
Iteration 114000, loss=0.45012107491493225
Iteration 114100, loss=0.7606402635574341
Iteration 114200, loss=0.00037366218748502433
Iteration 114300, loss=0.42511633038520813
Iteration 114400, loss=0.5073986053466797
Iteration 114500, loss=0.7669283151626587
Iteration 114600, loss=0.3724466860294342
Iteration 114700, loss=0.31920555233955383
Iteration 114800, loss=0.38764867186546326
Iteration 114900, loss=0.0323585607111454
Iteration 115000, loss=1.192093321833454e-07
Iteration 115100, loss=0.7241247892379761
Iteration 115200, loss=0.48693516850471497
Iteration 115300, loss=0.2709275186061859
Iteration 115400, loss=0.18738055229187012
Iteration 115500, loss=0.004714918788522482
Iteration 115600, loss=2.061298131942749
Iteration 115700, loss=2.8849059162894264e-05
Iteration 115800, loss=0.31056690216064453
Iteration 115900, loss=0.24933919310569763
Iteration 116000, loss=0.2604190409183502
Iteration 116100, loss=1.068598985671997
Iteration 116200, loss=0.47478610277175903
Iteration 116300, loss=1.6881822347640991
Iteration 116400, loss=0.874723494052887
Iteration 116500, loss=0.5251490473747253
Iteration 116600, loss=0.30457717180252075
Iteration 116700, loss=5.4956984968157485e-05
Iteration 116800, loss=4.124495506286621
Iteration 116900, loss=1.3924437761306763
Iteration 117000, loss=0.19856172800064087
Iteration 117100, loss=1.795159935951233
Iteration 117200, loss=0.2434016913175583
Iteration 117300, loss=0.7575507164001465
Iteration 117400, loss=0.9698912501335144
Iteration 117500, loss=0.5767992734909058
Iteration 117600, loss=0.044069334864616394
Iteration 117700, loss=0.4855068325996399
Iteration 117800, loss=1.192093321833454e-07
Iteration 117900, loss=0.36181169748306274
Iteration 118000, loss=4.962397575378418
Iteration 118100, loss=0.17737559974193573
Iteration 118200, loss=0.3924400806427002
Iteration 118300, loss=1.225560188293457
Iteration 118400, loss=0.4570843279361725
Iteration 118500, loss=0.3496425151824951
Iteration 118600, loss=0.31799036264419556
Iteration 118700, loss=0.04236653819680214
Iteration 118800, loss=0.24146969616413116
Iteration 118900, loss=0.3671174645423889
Iteration 119000, loss=0.22743678092956543
Iteration 119100, loss=1.192093321833454e-07
Iteration 119200, loss=1.0487655401229858
Iteration 119300, loss=0.01202947273850441
Iteration 119400, loss=0.3728988766670227
Iteration 119500, loss=0.9218728542327881
Iteration 119600, loss=3.099447440035874e-06
Iteration 119700, loss=0.39492854475975037
Iteration 119800, loss=2.7352542877197266
Iteration 119900, loss=0.31873205304145813
Iteration 120000, loss=0.34648773074150085
Nearest to that: have, you, i, our, out, not, was, the,
Nearest to the: you, in, that, there, but, have, i, ,,
Nearest to my: you, if, her, very, all, out, and, but,
Nearest to before: man, been, she, know, ., you, but, we,
Nearest to !: ", she, here, cried, ., to, you, we,
Nearest to if: you, there, not, that, to, have, one, the,
Nearest to could: you, not, tell, had, do, ?, come, all,
Nearest to .: you, me, and, ", was, have, now, the,
Nearest to over: to, the, i, man, you, there, were, with,
Nearest to what: you, ", said, see, ?, your, make, if,
Nearest to when: the, there, you, very, in, if, at, .,
Nearest to time: that, would, our, have, only, not, ,, for,
Nearest to ?: he, have, that, which, there, what, was, had,
Nearest to up: have, until, that, the, him, way, on, was,
Nearest to am: still, so, to, have, if, he, you, in,
Nearest to but: of, the, know, that, i, in, if, have,
Iteration 120100, loss=0.4138264060020447
Iteration 120200, loss=1.7881411622511223e-06
Iteration 120300, loss=0.4748106598854065
Iteration 120400, loss=0.33797669410705566
Iteration 120500, loss=0.42945072054862976
Iteration 120600, loss=0.31809723377227783
Iteration 120700, loss=0.1761932522058487
Iteration 120800, loss=0.5089570879936218
Iteration 120900, loss=1.192093321833454e-07
Iteration 121000, loss=0.21293221414089203
Iteration 121100, loss=1.192093321833454e-07
Iteration 121200, loss=0.43769371509552
Iteration 121300, loss=1.192093321833454e-07
Iteration 121400, loss=0.36391565203666687
Iteration 121500, loss=3.5762843708653236e-06
Iteration 121600, loss=0.00045256121666170657
Iteration 121700, loss=0.3283785283565521
Iteration 121800, loss=2.4716854095458984
Iteration 121900, loss=1.0496902465820312
Iteration 122000, loss=0.2617529630661011
Iteration 122100, loss=0.02964869700372219
Iteration 122200, loss=0.5665958523750305
Iteration 122300, loss=2.068490982055664
Iteration 122400, loss=0.40306222438812256
Iteration 122500, loss=0.343831866979599
Iteration 122600, loss=1.192093321833454e-07
Iteration 122700, loss=0.26392945647239685
Iteration 122800, loss=6.675744316453347e-06
Iteration 122900, loss=0.0006810362683609128
Iteration 123000, loss=0.3040297329425812
Iteration 123100, loss=0.0010919570922851562
Iteration 123200, loss=1.3030803203582764
Iteration 123300, loss=1.192093321833454e-07
Iteration 123400, loss=0.8494968414306641
Iteration 123500, loss=0.22890672087669373
Iteration 123600, loss=0.3199188709259033
Iteration 123700, loss=1.8437000513076782
Iteration 123800, loss=0.36517953872680664
Iteration 123900, loss=1.192093321833454e-07
Iteration 124000, loss=0.3097423017024994
Iteration 124100, loss=0.3706912696361542
Iteration 124200, loss=0.019489571452140808
Iteration 124300, loss=0.05506431683897972
Iteration 124400, loss=0.2114747315645218
Iteration 124500, loss=0.04458934813737869
Iteration 124600, loss=0.2657042145729065
Iteration 124700, loss=4.768372718899627e-07
Iteration 124800, loss=0.3655553460121155
Iteration 124900, loss=2.7243053913116455
Iteration 125000, loss=0.2725851535797119
Iteration 125100, loss=0.2645847797393799
Iteration 125200, loss=0.3845607340335846
Iteration 125300, loss=3.5686659812927246
Iteration 125400, loss=0.19325633347034454
Iteration 125500, loss=0.24914853274822235
Iteration 125600, loss=0.0002704628568608314
Iteration 125700, loss=0.30709534883499146
Iteration 125800, loss=0.20618027448654175
Iteration 125900, loss=0.05330614000558853
Iteration 126000, loss=0.09479501098394394
Iteration 126100, loss=1.192093321833454e-07
Iteration 126200, loss=0.43328747153282166
Iteration 126300, loss=0.32584503293037415
Iteration 126400, loss=0.9086461067199707
Iteration 126500, loss=1.380135178565979
Iteration 126600, loss=0.07166445255279541
Iteration 126700, loss=0.05421650782227516
Iteration 126800, loss=8.940734005591366e-06
Iteration 126900, loss=0.5190257430076599
Iteration 127000, loss=7.99223518371582
Iteration 127100, loss=0.27907320857048035
Iteration 127200, loss=0.31028103828430176
Iteration 127300, loss=0.21403834223747253
Iteration 127400, loss=0.3187883198261261
Iteration 127500, loss=0.1898312121629715
Iteration 127600, loss=0.3782418370246887
Iteration 127700, loss=0.15220396220684052
Iteration 127800, loss=0.24443663656711578
Iteration 127900, loss=0.2320162057876587
Iteration 128000, loss=0.25002872943878174
Iteration 128100, loss=1.192093321833454e-07
Iteration 128200, loss=0.2439797967672348
Iteration 128300, loss=0.24195201694965363
Iteration 128400, loss=1.192093321833454e-07
Iteration 128500, loss=0.21086792647838593
Iteration 128600, loss=0.44026827812194824
Iteration 128700, loss=0.21676543354988098
Iteration 128800, loss=0.379391074180603
Iteration 128900, loss=5.16551399230957
Iteration 129000, loss=0.22017909586429596
Iteration 129100, loss=0.2736319899559021
Iteration 129200, loss=0.1894281804561615
Iteration 129300, loss=0.3336939513683319
Iteration 129400, loss=0.2525154948234558
Iteration 129500, loss=0.0012999874306842685
Iteration 129600, loss=0.09330441057682037
Iteration 129700, loss=0.0004510109138209373
Iteration 129800, loss=2.3841853646899835e-07
Iteration 129900, loss=1.2039576768875122
Iteration 130000, loss=4.768372718899627e-07
Nearest to that: out, he, have, was, not, the, at, you,
Nearest to the: in, you, there, a, that, one, know, him,
Nearest to my: you, out, she, not, have, her, i, door,
Nearest to before: but, man, my, know, you, we, in, she,
Nearest to !: ", will, she, cried, here, ', ., if,
Nearest to if: you, will, she, there, to, one, not, we,
Nearest to could: you, not, as, come, have, tell, do, ?,
Nearest to .: have, one, ", the, me, it, now, you,
Nearest to over: there, i, to, but, man, were, was, which,
Nearest to what: you, said, ", she, ?, make, be, there,
Nearest to when: there, very, at, door, have, out, the, you,
Nearest to time: we, my, would, i, our, have, only, not,
Nearest to ?: have, would, ', should, had, if, here, ",
Nearest to up: the, him, were, way, have, that, until, you,
Nearest to am: one, have, my, you, i, that, as, in,
Nearest to but: one, know, has, in, which, there, of, that,
Iteration 130100, loss=2.9265084266662598
Iteration 130200, loss=0.19841226935386658
Iteration 130300, loss=0.19991762936115265
Iteration 130400, loss=1.7166277757496573e-05
Iteration 130500, loss=0.7798336744308472
Iteration 130600, loss=0.0003355112858116627
Iteration 130700, loss=1.572339653968811
Iteration 130800, loss=0.905327558517456
Iteration 130900, loss=0.33479076623916626
Iteration 131000, loss=2.4795843273750506e-05
Iteration 131100, loss=0.0007015543524175882
Iteration 131200, loss=0.2892775535583496
Iteration 131300, loss=0.7432492971420288
Iteration 131400, loss=0.3076840937137604
Iteration 131500, loss=0.15973667800426483
Iteration 131600, loss=1.192093321833454e-07
Iteration 131700, loss=0.02532927505671978
Iteration 131800, loss=0.28053170442581177
Iteration 131900, loss=0.4529896378517151
Iteration 132000, loss=2.1837544441223145
Iteration 132100, loss=6.437320735130925e-06
Iteration 132200, loss=0.863743782043457
Iteration 132300, loss=1.192093321833454e-07
Iteration 132400, loss=0.8183237314224243
Iteration 132500, loss=0.2467460036277771
Iteration 132600, loss=1.6706466674804688
Iteration 132700, loss=0.9992046356201172
Iteration 132800, loss=0.10553519427776337
Iteration 132900, loss=1.083975911140442
Iteration 133000, loss=0.015885328873991966
Iteration 133100, loss=0.33154168725013733
Iteration 133200, loss=0.04245235025882721
Iteration 133300, loss=0.21656890213489532
Iteration 133400, loss=0.05897800624370575
Iteration 133500, loss=0.20279423892498016
Iteration 133600, loss=0.26740583777427673
Iteration 133700, loss=0.22245116531848907
Iteration 133800, loss=0.22683458030223846
Iteration 133900, loss=1.306990385055542
Iteration 134000, loss=0.2154652625322342
Iteration 134100, loss=1.4632344245910645
Iteration 134200, loss=0.6439999341964722
Iteration 134300, loss=0.24327285587787628
Iteration 134400, loss=1.192093321833454e-07
Iteration 134500, loss=3.6980204582214355
Iteration 134600, loss=0.2616642713546753
Iteration 134700, loss=1.0298869609832764
Iteration 134800, loss=0.3596647083759308
Iteration 134900, loss=0.10852877050638199
Iteration 135000, loss=0.27271750569343567
Iteration 135100, loss=0.7705473899841309
Iteration 135200, loss=0.0038875702302902937
Iteration 135300, loss=0.25480106472969055
Iteration 135400, loss=0.2872557044029236
Iteration 135500, loss=0.34573203325271606
Iteration 135600, loss=0.24512122571468353
Iteration 135700, loss=0.036191970109939575
Iteration 135800, loss=0.2925500273704529
Iteration 135900, loss=2.01094651222229
Iteration 136000, loss=0.5859442353248596
Iteration 136100, loss=0.19421492516994476
Iteration 136200, loss=0.18668244779109955
Iteration 136300, loss=1.0101414918899536
Iteration 136400, loss=0.6527943015098572
Iteration 136500, loss=8.643049659440294e-05
Iteration 136600, loss=1.0850310325622559
Iteration 136700, loss=6.782812118530273
Iteration 136800, loss=1.1931195259094238
Iteration 136900, loss=0.5615662336349487
Iteration 137000, loss=1.340600609779358
Iteration 137100, loss=1.192093321833454e-07
Iteration 137200, loss=0.24816203117370605
Iteration 137300, loss=0.6641989946365356
Iteration 137400, loss=0.18390047550201416
Iteration 137500, loss=0.7855033278465271
Iteration 137600, loss=0.21267423033714294
Iteration 137700, loss=7.77036190032959
Iteration 137800, loss=0.012376404367387295
Iteration 137900, loss=0.27635657787323
Iteration 138000, loss=1.0047427415847778
Iteration 138100, loss=2.0974221229553223
Iteration 138200, loss=0.1551394909620285
Iteration 138300, loss=0.15308056771755219
Iteration 138400, loss=0.9385856986045837
Iteration 138500, loss=0.2035771757364273
Iteration 138600, loss=0.00042071842472068965
Iteration 138700, loss=0.29493817687034607
Iteration 138800, loss=1.8271682262420654
Iteration 138900, loss=1.192093321833454e-07
Iteration 139000, loss=1.192093321833454e-07
Iteration 139100, loss=1.192093321833454e-07
Iteration 139200, loss=0.19835321605205536
Iteration 139300, loss=0.29268497228622437
Iteration 139400, loss=1.504274845123291
Iteration 139500, loss=0.015925727784633636
Iteration 139600, loss=0.18554915487766266
Iteration 139700, loss=0.10907915234565735
Iteration 139800, loss=0.3237500786781311
Iteration 139900, loss=1.1683025360107422
Iteration 140000, loss=0.21983754634857178
Nearest to that: out, he, i, not, was, two, my, have,
Nearest to the: in, you, there, a, at, ,, one, with,
Nearest to my: out, you, have, i, that, me, not, was,
Nearest to before: my, man, but, been, done, i, she, we,
Nearest to !: ", will, she, did, to, if, ', was,
Nearest to if: will, i, to, you, my, me, be, were,
Nearest to could: you, not, be, come, tell, as, has, all,
Nearest to .: ", me, was, have, you, now, it, the,
Nearest to over: was, were, to, i, you, man, the, out,
Nearest to what: ", you, said, she, your, i, there, make,
Nearest to when: there, very, from, even, have, at, you, as,
Nearest to time: my, her, me, know, our, have, i, you,
Nearest to ?: of, know, had, ', was, ", that, were,
Nearest to up: have, were, when, that, been, him, back, you,
Nearest to am: have, my, be, you, glad, no, could, still,
Nearest to but: has, out, my, have, know, of, was, he,
Iteration 140100, loss=1.6138052940368652
Iteration 140200, loss=1.192093321833454e-07
Iteration 140300, loss=1.643237829208374
Iteration 140400, loss=5.602852979791351e-06
Iteration 140500, loss=0.3575602173805237
Iteration 140600, loss=0.2585272789001465
Iteration 140700, loss=0.18584635853767395
Iteration 140800, loss=3.5120961666107178
Iteration 140900, loss=0.310093492269516
Iteration 141000, loss=0.18387967348098755
Iteration 141100, loss=0.2125457376241684
Iteration 141200, loss=0.44756031036376953
Iteration 141300, loss=3.002687454223633
Iteration 141400, loss=0.863693356513977
Iteration 141500, loss=0.33432814478874207
Iteration 141600, loss=1.4281922578811646
Iteration 141700, loss=0.014516908675432205
Iteration 141800, loss=1.0651692152023315
Iteration 141900, loss=0.41285091638565063
Iteration 142000, loss=1.192093321833454e-07
Iteration 142100, loss=0.23753395676612854
Iteration 142200, loss=0.04241254925727844
Iteration 142300, loss=0.2593420743942261
Iteration 142400, loss=0.7803162336349487
Iteration 142500, loss=5.56085205078125
Iteration 142600, loss=0.07068032771348953
Iteration 142700, loss=0.08785968273878098
Iteration 142800, loss=1.7445054054260254
Iteration 142900, loss=1.4053572416305542
Iteration 143000, loss=3.7047550678253174
Iteration 143100, loss=0.2143932282924652
Iteration 143200, loss=0.23885031044483185
Iteration 143300, loss=1.192093321833454e-07
Iteration 143400, loss=1.192093321833454e-07
Iteration 143500, loss=0.0005664642085321248
Iteration 143600, loss=1.6596934795379639
Iteration 143700, loss=0.3548954725265503
Iteration 143800, loss=0.24399736523628235
Iteration 143900, loss=1.192093321833454e-07
Iteration 144000, loss=0.160222128033638
Iteration 144100, loss=0.9355545043945312
Iteration 144200, loss=2.3841853646899835e-07
Iteration 144300, loss=3.0789945125579834
Iteration 144400, loss=0.35762056708335876
Iteration 144500, loss=0.2681167423725128
Iteration 144600, loss=0.313155859708786
Iteration 144700, loss=0.3173297941684723
Iteration 144800, loss=0.18451739847660065
Iteration 144900, loss=0.3052847981452942
Iteration 145000, loss=0.12646622955799103
Iteration 145100, loss=0.7421903610229492
Iteration 145200, loss=0.2530613839626312
Iteration 145300, loss=3.2858850955963135
Iteration 145400, loss=0.23173795640468597
Iteration 145500, loss=0.028972623869776726
Iteration 145600, loss=0.02114189974963665
Iteration 145700, loss=2.3892133235931396
Iteration 145800, loss=0.014052017591893673
Iteration 145900, loss=0.511709988117218
Iteration 146000, loss=0.712916910648346
Iteration 146100, loss=0.358608603477478
Iteration 146200, loss=1.192093321833454e-07
Iteration 146300, loss=1.192093321833454e-07
Iteration 146400, loss=0.2365020215511322
Iteration 146500, loss=0.23688629269599915
Iteration 146600, loss=4.961493968963623
Iteration 146700, loss=1.192093321833454e-07
Iteration 146800, loss=0.21488621830940247
Iteration 146900, loss=0.8875578045845032
Iteration 147000, loss=1.192093321833454e-07
Iteration 147100, loss=3.576278118089249e-07
Iteration 147200, loss=1.192093321833454e-07
Iteration 147300, loss=0.3007354736328125
Iteration 147400, loss=0.7146152853965759
Iteration 147500, loss=0.021933263167738914
Iteration 147600, loss=0.0011193457758054137
Iteration 147700, loss=0.36795127391815186
Iteration 147800, loss=0.65398770570755
Iteration 147900, loss=0.3100544512271881
Iteration 148000, loss=0.0006092257681302726
Iteration 148100, loss=0.4862886369228363
Iteration 148200, loss=0.16040916740894318
Iteration 148300, loss=1.192093321833454e-07
Iteration 148400, loss=1.1870659589767456
Iteration 148500, loss=1.192093321833454e-07
Iteration 148600, loss=0.13750667870044708
Iteration 148700, loss=1.192093321833454e-07
Iteration 148800, loss=1.3421058654785156
Iteration 148900, loss=0.9075024127960205
Iteration 149000, loss=1.3410494327545166
Iteration 149100, loss=0.9496473073959351
Iteration 149200, loss=0.22737175226211548
Iteration 149300, loss=0.21277576684951782
Iteration 149400, loss=0.11795402318239212
Iteration 149500, loss=0.2266613095998764
Iteration 149600, loss=1.192093321833454e-07
Iteration 149700, loss=0.32437795400619507
Iteration 149800, loss=0.1707468032836914
Iteration 149900, loss=0.29713350534439087
Iteration 150000, loss=0.24426843225955963
Nearest to that: he, but, i, out, for, very, was, you,
Nearest to the: in, a, he, that, for, upon, and, you,
Nearest to my: very, you, she, as, that, for, door, then,
Nearest to before: man, very, my, we, but, ?, been, she,
Nearest to !: ", she, will, ?, here, was, we, me,
Nearest to if: he, to, you, i, will, but, there, was,
Nearest to could: as, has, you, not, all, tell, with, had,
Nearest to .: ", was, he, me, but, very, it, have,
Nearest to over: but, out, to, was, two, man, you, one,
Nearest to what: ", everything, will, you, she, your, no, are,
Nearest to when: there, you, but, a, as, very, at, i,
Nearest to time: my, but, at, ?, i, know, sat, upon,
Nearest to ?: had, that, should, but, no, ", i, see,
Nearest to up: him, were, when, by, he, have, at, until,
Nearest to am: but, my, no, have, he, when, in, as,
Nearest to but: that, he, has, in, was, very, i, which,
Iteration 150100, loss=0.01132595632225275
Iteration 150200, loss=1.0796082019805908
Iteration 150300, loss=0.15332169830799103
Iteration 150400, loss=1.4845894575119019
Iteration 150500, loss=0.2949611246585846
Iteration 150600, loss=0.32135143876075745
Iteration 150700, loss=0.3975241780281067
Iteration 150800, loss=3.6963396072387695
Iteration 150900, loss=3.159094922011718e-05
Iteration 151000, loss=0.22194156050682068
Iteration 151100, loss=1.192093321833454e-07
Iteration 151200, loss=0.30873167514801025
Iteration 151300, loss=0.23524565994739532
Iteration 151400, loss=0.2247491478919983
Iteration 151500, loss=0.16350284218788147
Iteration 151600, loss=9.56733512878418
Iteration 151700, loss=0.3413027226924896
Iteration 151800, loss=0.019948549568653107
Iteration 151900, loss=3.737380027770996
Iteration 152000, loss=2.735144853591919
Iteration 152100, loss=0.24966047704219818
Iteration 152200, loss=0.0006373171345330775
Iteration 152300, loss=0.024877671152353287
Iteration 152400, loss=0.403959184885025
Iteration 152500, loss=0.10939271003007889
Iteration 152600, loss=0.02553800493478775
Iteration 152700, loss=0.6705116629600525
Iteration 152800, loss=1.6096054315567017
Iteration 152900, loss=1.192093321833454e-07
Iteration 153000, loss=0.2861950397491455
Iteration 153100, loss=0.38207894563674927
Iteration 153200, loss=0.2526435852050781
Iteration 153300, loss=0.3512531816959381
Iteration 153400, loss=2.626915454864502
Iteration 153500, loss=0.04111946374177933
Iteration 153600, loss=1.192093321833454e-07
Iteration 153700, loss=0.2900327146053314
Iteration 153800, loss=0.17538049817085266
Iteration 153900, loss=0.2720712423324585
Iteration 154000, loss=0.3311772346496582
Iteration 154100, loss=5.93679906160105e-05
Iteration 154200, loss=0.00028799157007597387
Iteration 154300, loss=0.30114778876304626
Iteration 154400, loss=1.9733996391296387
Iteration 154500, loss=1.1661372184753418
Iteration 154600, loss=0.29864293336868286
Iteration 154700, loss=2.3841853646899835e-07
Iteration 154800, loss=1.192093321833454e-07
Iteration 154900, loss=0.421364426612854
Iteration 155000, loss=2.022564172744751
Iteration 155100, loss=1.4156768321990967
Iteration 155200, loss=0.21199259161949158
Iteration 155300, loss=3.5843684673309326
Iteration 155400, loss=0.29619544744491577
Iteration 155500, loss=1.192093321833454e-07
Iteration 155600, loss=0.31531792879104614
Iteration 155700, loss=0.04067773371934891
Iteration 155800, loss=0.05770772323012352
Iteration 155900, loss=0.17280706763267517
Iteration 156000, loss=2.2861695289611816
Iteration 156100, loss=0.27045971155166626
Iteration 156200, loss=0.18273445963859558
Iteration 156300, loss=0.016921304166316986
Iteration 156400, loss=0.6667953133583069
Iteration 156500, loss=0.2724318504333496
Iteration 156600, loss=1.192093321833454e-07
Iteration 156700, loss=0.12478641420602798
Iteration 156800, loss=0.15263432264328003
Iteration 156900, loss=0.27279728651046753
Iteration 157000, loss=0.07748610526323318
Iteration 157100, loss=0.19235637784004211
Iteration 157200, loss=1.192093321833454e-07
Iteration 157300, loss=6.854766979813576e-05
Iteration 157400, loss=0.1803256720304489
Iteration 157500, loss=0.32141000032424927
Iteration 157600, loss=0.13606983423233032
Iteration 157700, loss=0.2537039816379547
Iteration 157800, loss=1.192093321833454e-07
Iteration 157900, loss=0.22343900799751282
Iteration 158000, loss=1.192093321833454e-07
Iteration 158100, loss=0.7742229700088501
Iteration 158200, loss=0.0038209748454391956
Iteration 158300, loss=0.23592235147953033
Iteration 158400, loss=1.192093321833454e-07
Iteration 158500, loss=0.28566914796829224
Iteration 158600, loss=0.27386847138404846
Iteration 158700, loss=0.3659268021583557
Iteration 158800, loss=0.46205538511276245
Iteration 158900, loss=0.30033358931541443
Iteration 159000, loss=4.911544965580106e-05
Iteration 159100, loss=0.2636781334877014
Iteration 159200, loss=0.177310511469841
Iteration 159300, loss=0.11255637556314468
Iteration 159400, loss=1.192093321833454e-07
Iteration 159500, loss=0.4366425573825836
Iteration 159600, loss=0.38812920451164246
Iteration 159700, loss=0.23024263978004456
Iteration 159800, loss=1.385475516319275
Iteration 159900, loss=1.192093321833454e-07
Iteration 160000, loss=0.18300002813339233
Nearest to that: he, out, but, have, be, no, i, was,
Nearest to the: there, in, a, as, when, that, he, him,
Nearest to my: as, one, even, must, all, have, he, you,
Nearest to before: but, man, ?, my, ., as, she, in,
Nearest to !: ", she, ?, will, even, was, but, here,
Nearest to if: he, you, that, to, i, will, there, one,
Nearest to could: not, you, ?, if, he, no, had, as,
Nearest to .: which, have, one, me, was, and, but, it,
Nearest to over: but, which, was, one, out, to, were, you,
Nearest to what: ", will, everything, she, your, no, said, you,
Nearest to when: there, as, you, the, a, to, only, very,
Nearest to time: have, but, in, ,, know, her, i, that,
Nearest to ?: should, ", even, be, had, that, see, how,
Nearest to up: when, have, him, in, put, were, had, a,
Nearest to am: but, ., it, have, to, as, no, one,
Nearest to but: he, which, that, one, out, even, i, everything,
Iteration 160100, loss=1.1914693117141724
Iteration 160200, loss=0.26237595081329346
Iteration 160300, loss=0.23545271158218384
Iteration 160400, loss=1.3587901592254639
Iteration 160500, loss=0.270658016204834
Iteration 160600, loss=0.309037446975708
Iteration 160700, loss=0.15127085149288177
Iteration 160800, loss=0.3813781142234802
Iteration 160900, loss=1.192093321833454e-07
Iteration 161000, loss=0.3089001476764679
Iteration 161100, loss=0.2670217752456665
Iteration 161200, loss=0.2158995121717453
Iteration 161300, loss=0.24235108494758606
Iteration 161400, loss=3.98081111907959
Iteration 161500, loss=1.192093321833454e-07
Iteration 161600, loss=0.29629048705101013
Iteration 161700, loss=1.574251651763916
Iteration 161800, loss=0.28811967372894287
Iteration 161900, loss=3.4570762181829195e-06
Iteration 162000, loss=1.192093321833454e-07
Iteration 162100, loss=0.05821667239069939
Iteration 162200, loss=0.1565363109111786
Iteration 162300, loss=0.45148468017578125
Iteration 162400, loss=1.5098581314086914
Iteration 162500, loss=0.3313329815864563
Iteration 162600, loss=4.768372718899627e-07
Iteration 162700, loss=0.3574179708957672
Iteration 162800, loss=1.0013628525484819e-05
Iteration 162900, loss=2.610717092466075e-05
Iteration 163000, loss=0.2680051028728485
Iteration 163100, loss=2.3841853646899835e-07
Iteration 163200, loss=1.9091533422470093
Iteration 163300, loss=2.492017984390259
Iteration 163400, loss=11.624897003173828
Iteration 163500, loss=0.2343444526195526
Iteration 163600, loss=0.00014735352306161076
Iteration 163700, loss=0.2273433804512024
Iteration 163800, loss=0.18918894231319427
Iteration 163900, loss=1.192093321833454e-07
Iteration 164000, loss=0.21224509179592133
Iteration 164100, loss=0.7967524528503418
Iteration 164200, loss=0.10170814394950867
Iteration 164300, loss=1.5346380472183228
Iteration 164400, loss=1.2791813611984253
Iteration 164500, loss=0.09434162825345993
Iteration 164600, loss=2.013653039932251
Iteration 164700, loss=1.192093321833454e-07
Iteration 164800, loss=0.005785479675978422
Iteration 164900, loss=1.807058572769165
Iteration 165000, loss=0.2591068744659424
Iteration 165100, loss=0.9210563898086548
Iteration 165200, loss=2.618896484375
Iteration 165300, loss=0.2727818787097931
Iteration 165400, loss=1.192093321833454e-07
Iteration 165500, loss=0.2649801969528198
Iteration 165600, loss=0.0008753194706514478
Iteration 165700, loss=0.24417345225811005
Iteration 165800, loss=0.4881546199321747
Iteration 165900, loss=1.0398693084716797
Iteration 166000, loss=0.2608255445957184
Iteration 166100, loss=0.6453575491905212
Iteration 166200, loss=0.2717251479625702
Iteration 166300, loss=1.192093321833454e-07
Iteration 166400, loss=0.25119489431381226
Iteration 166500, loss=2.145769030903466e-06
Iteration 166600, loss=0.2985597848892212
Iteration 166700, loss=0.1762775033712387
Iteration 166800, loss=0.3589954376220703
Iteration 166900, loss=1.5174260139465332
Iteration 167000, loss=3.5762843708653236e-06
Iteration 167100, loss=0.0012776070507243276
Iteration 167200, loss=0.0004335986159276217
Iteration 167300, loss=0.47342267632484436
Iteration 167400, loss=0.23362094163894653
Iteration 167500, loss=1.2323393821716309
Iteration 167600, loss=0.2629173994064331
Iteration 167700, loss=0.26845526695251465
Iteration 167800, loss=0.20625253021717072
Iteration 167900, loss=0.16139055788516998
Iteration 168000, loss=0.23917759954929352
Iteration 168100, loss=9.536747711536009e-07
Iteration 168200, loss=0.3837927281856537
Iteration 168300, loss=0.9424894452095032
Iteration 168400, loss=0.23321713507175446
Iteration 168500, loss=0.17054252326488495
Iteration 168600, loss=1.192093321833454e-07
Iteration 168700, loss=0.24565382301807404
Iteration 168800, loss=0.3510861396789551
Iteration 168900, loss=0.17190849781036377
Iteration 169000, loss=0.18122872710227966
Iteration 169100, loss=0.48915424942970276
Iteration 169200, loss=0.19694970548152924
Iteration 169300, loss=0.3042423129081726
Iteration 169400, loss=0.2997819483280182
Iteration 169500, loss=0.02839125692844391
Iteration 169600, loss=4.221930980682373
Iteration 169700, loss=0.5061390995979309
Iteration 169800, loss=0.06731826812028885
Iteration 169900, loss=0.303154319524765
Iteration 170000, loss=0.1546747088432312
Nearest to that: he, was, now, out, no, but, my, had,
Nearest to the: but, when, have, ,, in, was, a, him,
Nearest to my: have, even, out, that, all, one, he, you,
Nearest to before: but, have, she, which, ?, my, been, him,
Nearest to !: ", she, me, here, will, did,  , our,
Nearest to if: there, you, will, he, one, that, ?, when,
Nearest to could: not, as, have, tell, had, you, ?, he,
Nearest to .: have, which, but, was, one, and, him, ",
Nearest to over: but, to, which, there, out, was, last, you,
Nearest to what: ", your, even, everything, you, will, be, ?,
Nearest to when: as, the, in, you, have, is, be, even,
Nearest to time: our, but, out, upon, how, have, i, matter,
Nearest to ?: should, out, but, all, be, have, will, even,
Nearest to up: have, when, put, him, had, in, until, should,
Nearest to am: one, but, have, if, as, when, in, no,
Nearest to but: which, in, have, that, here, even, was, there,
Iteration 170100, loss=1.4912928342819214
Iteration 170200, loss=0.05480546876788139
Iteration 170300, loss=0.18040324747562408
Iteration 170400, loss=1.192093321833454e-07
Iteration 170500, loss=0.2666926980018616
Iteration 170600, loss=3.576278118089249e-07
Iteration 170700, loss=1.2551500797271729
Iteration 170800, loss=0.4380094110965729
Iteration 170900, loss=1.192093321833454e-07
Iteration 171000, loss=0.18609093129634857
Iteration 171100, loss=0.4453109800815582
Iteration 171200, loss=0.9321101903915405
Iteration 171300, loss=2.003485918045044
Iteration 171400, loss=1.211921215057373
Iteration 171500, loss=0.24963687360286713
Iteration 171600, loss=1.192093321833454e-07
Iteration 171700, loss=0.18766754865646362
Iteration 171800, loss=1.192093321833454e-07
Iteration 171900, loss=1.192093321833454e-07
Iteration 172000, loss=0.0007920420030131936
Iteration 172100, loss=1.4107705354690552
Iteration 172200, loss=0.276168555021286
Iteration 172300, loss=0.07851797342300415
Iteration 172400, loss=0.24615083634853363
Iteration 172500, loss=1.192093321833454e-07
Iteration 172600, loss=0.017945583909749985
Iteration 172700, loss=2.514742612838745
Iteration 172800, loss=0.19503654539585114
Iteration 172900, loss=1.192093321833454e-07
Iteration 173000, loss=0.0003221553342882544
Iteration 173100, loss=0.000167145422892645
Iteration 173200, loss=0.11219439655542374
Iteration 173300, loss=0.1259075552225113
Iteration 173400, loss=0.2620140016078949
Iteration 173500, loss=1.1430821418762207
Iteration 173600, loss=0.22112949192523956
Iteration 173700, loss=3.689850330352783
Iteration 173800, loss=0.07269810885190964
Iteration 173900, loss=0.042225755751132965
Iteration 174000, loss=0.0007612052722834051
Iteration 174100, loss=4.98307344969362e-05
Iteration 174200, loss=0.16520050168037415
Iteration 174300, loss=0.4046095609664917
Iteration 174400, loss=0.3851660490036011
Iteration 174500, loss=0.24380795657634735
Iteration 174600, loss=0.001825567102059722
Iteration 174700, loss=0.5605556964874268
Iteration 174800, loss=0.2637365162372589
Iteration 174900, loss=0.3338921070098877
Iteration 175000, loss=0.3839298486709595
Iteration 175100, loss=0.23868487775325775
Iteration 175200, loss=0.012274820357561111
Iteration 175300, loss=0.0004671710485126823
Iteration 175400, loss=0.22650648653507233
Iteration 175500, loss=0.002682883758097887
Iteration 175600, loss=1.5554957389831543
Iteration 175700, loss=1.3417510986328125
Iteration 175800, loss=1.192093321833454e-07
Iteration 175900, loss=0.09580986946821213
Iteration 176000, loss=1.192093321833454e-07
Iteration 176100, loss=0.12660573422908783
Iteration 176200, loss=0.25509199500083923
Iteration 176300, loss=1.192093321833454e-07
Iteration 176400, loss=0.26507943868637085
Iteration 176500, loss=0.25582730770111084
Iteration 176600, loss=0.16004852950572968
Iteration 176700, loss=0.17152124643325806
Iteration 176800, loss=0.26150980591773987
Iteration 176900, loss=0.3365112543106079
Iteration 177000, loss=1.2344818115234375
Iteration 177100, loss=0.8136960864067078
Iteration 177200, loss=1.192093321833454e-07
Iteration 177300, loss=1.192093321833454e-07
Iteration 177400, loss=1.449398159980774
Iteration 177500, loss=0.691634476184845
Iteration 177600, loss=1.232203483581543
Iteration 177700, loss=0.007648375816643238
Iteration 177800, loss=0.27379828691482544
Iteration 177900, loss=0.8679256439208984
Iteration 178000, loss=0.32769280672073364
Iteration 178100, loss=0.17860552668571472
Iteration 178200, loss=1.1925785541534424
Iteration 178300, loss=2.6226073259749683e-06
Iteration 178400, loss=0.3606242537498474
Iteration 178500, loss=0.21390992403030396
Iteration 178600, loss=0.2931939363479614
Iteration 178700, loss=0.28531602025032043
Iteration 178800, loss=0.005388746038079262
Iteration 178900, loss=1.192093321833454e-07
Iteration 179000, loss=0.09283376485109329
Iteration 179100, loss=0.12930940091609955
Iteration 179200, loss=0.11256985366344452
Iteration 179300, loss=0.2539217174053192
Iteration 179400, loss=1.057910442352295
Iteration 179500, loss=0.7812185287475586
Iteration 179600, loss=1.548622727394104
Iteration 179700, loss=0.18385174870491028
Iteration 179800, loss=0.3997703194618225
Iteration 179900, loss=0.8748783469200134
Iteration 180000, loss=0.007018761709332466
Nearest to that: out, he, my, was, but, now, have, be,
Nearest to the: there, in, ,, upon, out, know, but, a,
Nearest to my: as, all, out, have, that, he, you, me,
Nearest to before: but, man, out, know, my, have, could, all,
Nearest to !: ", ?, ', did, will, table, me, here,
Nearest to if: i, you, but, he, that, will, my, one,
Nearest to could: come, has, will, my, have, ?, know, all,
Nearest to .: but, with, have, which, he, one, and, as,
Nearest to over: but, there, to, out, know, was, were, one,
Nearest to what: your, ", everything, can, ?, you, see, be,
Nearest to when: as, heard, you, there, my, be, that, i,
Nearest to time: have, but, even, could, has, in, only, should,
Nearest to ?: should, that, be, even, out, your, my, have,
Nearest to up: have, when, put, him, on, in, a, has,
Nearest to am: one, as, have, if, no, be, you, make,
Nearest to but: out, he, here, that, which, in, if, my,
Iteration 180100, loss=0.012755941599607468
Iteration 180200, loss=1.2123360633850098
Iteration 180300, loss=0.3699055016040802
Iteration 180400, loss=0.16467957198619843
Iteration 180500, loss=3.576278118089249e-07
Iteration 180600, loss=0.22146309912204742
Iteration 180700, loss=0.2089400738477707
Iteration 180800, loss=1.192093321833454e-07
Iteration 180900, loss=0.25156718492507935
Iteration 181000, loss=1.3947577826911584e-05
Iteration 181100, loss=0.38667017221450806
Iteration 181200, loss=1.192093321833454e-07
Iteration 181300, loss=0.09433732181787491
Iteration 181400, loss=1.0437594652175903
Iteration 181500, loss=1.0464966297149658
Iteration 181600, loss=0.2804816961288452
Iteration 181700, loss=1.4925041198730469
Iteration 181800, loss=0.30909663438796997
Iteration 181900, loss=0.2701963484287262
Iteration 182000, loss=4.2747931480407715
Iteration 182100, loss=0.6816325783729553
Iteration 182200, loss=0.238804891705513
Iteration 182300, loss=0.3581560552120209
Iteration 182400, loss=0.2845047414302826
Iteration 182500, loss=0.011643268167972565
Iteration 182600, loss=1.3950875997543335
Iteration 182700, loss=0.28475162386894226
Iteration 182800, loss=0.127436563372612
Iteration 182900, loss=0.2718292474746704
Iteration 183000, loss=0.3639841079711914
Iteration 183100, loss=0.2978450357913971
Iteration 183200, loss=0.2665224075317383
Iteration 183300, loss=0.355288028717041
Iteration 183400, loss=1.2612123489379883
Iteration 183500, loss=1.994035005569458
Iteration 183600, loss=0.08763135969638824
Iteration 183700, loss=1.192093321833454e-07
Iteration 183800, loss=0.003727519419044256
Iteration 183900, loss=1.192093321833454e-07
Iteration 184000, loss=0.4968499541282654
Iteration 184100, loss=0.6435927152633667
Iteration 184200, loss=0.2529560327529907
Iteration 184300, loss=0.2235407531261444
Iteration 184400, loss=1.962162971496582
Iteration 184500, loss=0.027663400396704674
Iteration 184600, loss=1.192093321833454e-07
Iteration 184700, loss=1.1974239349365234
Iteration 184800, loss=0.37697264552116394
Iteration 184900, loss=0.18745467066764832
Iteration 185000, loss=0.2558254897594452
Iteration 185100, loss=1.6451022020191886e-05
Iteration 185200, loss=0.04732682555913925
Iteration 185300, loss=1.2222659587860107
Iteration 185400, loss=0.4931188225746155
Iteration 185500, loss=0.061233412474393845
Iteration 185600, loss=0.015351708978414536
Iteration 185700, loss=0.595872163772583
Iteration 185800, loss=0.27145543694496155
Iteration 185900, loss=0.2733577489852905
Iteration 186000, loss=0.47847387194633484
Iteration 186100, loss=0.002903440035879612
Iteration 186200, loss=0.3692845106124878
Iteration 186300, loss=0.20888809859752655
Iteration 186400, loss=2.3481616973876953
Iteration 186500, loss=0.5703727602958679
Iteration 186600, loss=1.192093321833454e-07
Iteration 186700, loss=1.192093321833454e-07
Iteration 186800, loss=0.2494538426399231
Iteration 186900, loss=0.36553654074668884
Iteration 187000, loss=0.5906897783279419
Iteration 187100, loss=0.30082595348358154
Iteration 187200, loss=1.072765588760376
Iteration 187300, loss=0.14167629182338715
Iteration 187400, loss=0.3191632330417633
Iteration 187500, loss=0.3547971844673157
Iteration 187600, loss=1.5213850736618042
Iteration 187700, loss=0.4311749339103699
Iteration 187800, loss=1.192093321833454e-07
Iteration 187900, loss=1.2458956241607666
Iteration 188000, loss=0.21564939618110657
Iteration 188100, loss=1.422774076461792
Iteration 188200, loss=5.602852979791351e-06
Iteration 188300, loss=0.2366296947002411
Iteration 188400, loss=1.1205826997756958
Iteration 188500, loss=0.17392253875732422
Iteration 188600, loss=0.043815977871418
Iteration 188700, loss=0.543537437915802
Iteration 188800, loss=0.3425322473049164
Iteration 188900, loss=0.14573033154010773
Iteration 189000, loss=0.00012076627899659798
Iteration 189100, loss=0.4903688430786133
Iteration 189200, loss=0.00013376180140767246
Iteration 189300, loss=3.2186549105972517e-06
Iteration 189400, loss=0.4028451442718506
Iteration 189500, loss=0.1906505674123764
Iteration 189600, loss=0.7408422827720642
Iteration 189700, loss=1.2859938144683838
Iteration 189800, loss=0.2416006475687027
Iteration 189900, loss=1.192093321833454e-07
Iteration 190000, loss=0.23887424170970917
Nearest to that: he, door, out, no, was, i, ?, my,
Nearest to the: ,, there, out, in, were, one, any, door,
Nearest to my: as, have, out, but, all, that, you, it,
Nearest to before: but, she, ?, out, have, could, know, will,
Nearest to !: ', ", ?, did, one, here, even, no,
Nearest to if: he, i, you, ?, one, there, will, but,
Nearest to could: not, will, which, come, you, tell, ?, but,
Nearest to .: which, but, one, he, was, with, as, have,
Nearest to over: but, last, out, man, there, to, know, which,
Nearest to what: your, me, ?, ", even, which, and, be,
Nearest to when: be, you, as, man, heard, a, only, in,
Nearest to time: but, know, her, will, could, how, before, even,
Nearest to ?: should, have, that, he, if, were, be, only,
Nearest to up: have, a, on, when, him, back, were, to,
Nearest to am: one, if, in, my, as, ., he, was,
Nearest to but: here, which, out, one, even, he, my, .,
Iteration 190100, loss=0.04171773046255112
Iteration 190200, loss=5.808599948883057
Iteration 190300, loss=1.41977059841156
Iteration 190400, loss=2.6267595291137695
Iteration 190500, loss=1.806671142578125
Iteration 190600, loss=3.0258913040161133
Iteration 190700, loss=0.00011408983118599281
Iteration 190800, loss=0.1552836149930954
Iteration 190900, loss=2.3841853646899835e-07
Iteration 191000, loss=0.2010088562965393
Iteration 191100, loss=0.21362271904945374
Iteration 191200, loss=1.7270710468292236
Iteration 191300, loss=0.15693041682243347
Iteration 191400, loss=0.21593165397644043
Iteration 191500, loss=0.20772585272789001
Iteration 191600, loss=1.192093321833454e-07
Iteration 191700, loss=2.3841853646899835e-07
Iteration 191800, loss=1.3837554454803467
Iteration 191900, loss=0.3835121691226959
Iteration 192000, loss=0.292169451713562
Iteration 192100, loss=0.29947027564048767
Iteration 192200, loss=1.2278632311790716e-05
Iteration 192300, loss=0.24901950359344482
Iteration 192400, loss=0.26316291093826294
Iteration 192500, loss=0.16772325336933136
Iteration 192600, loss=0.19030135869979858
Iteration 192700, loss=0.11909335851669312
Iteration 192800, loss=1.192093321833454e-07
Iteration 192900, loss=0.17944134771823883
Iteration 193000, loss=1.192093321833454e-07
Iteration 193100, loss=0.001055380329489708
Iteration 193200, loss=5.006800165574532e-06
Iteration 193300, loss=0.28776219487190247
Iteration 193400, loss=0.9792944192886353
Iteration 193500, loss=1.192093321833454e-07
Iteration 193600, loss=0.21811799705028534
Iteration 193700, loss=0.164525106549263
Iteration 193800, loss=1.192093321833454e-07
Iteration 193900, loss=2.8326077461242676
Iteration 194000, loss=1.0201082229614258
Iteration 194100, loss=1.192093321833454e-07
Iteration 194200, loss=15.942384719848633
Iteration 194300, loss=0.0030537929851561785
Iteration 194400, loss=1.311302526119107e-06
Iteration 194500, loss=0.20243412256240845
Iteration 194600, loss=3.576278118089249e-07
Iteration 194700, loss=0.46839064359664917
Iteration 194800, loss=0.2030957043170929
Iteration 194900, loss=1.6557155847549438
Iteration 195000, loss=1.192093321833454e-07
Iteration 195100, loss=1.2215174436569214
Iteration 195200, loss=0.2016454041004181
Iteration 195300, loss=0.39773428440093994
Iteration 195400, loss=0.30332672595977783
Iteration 195500, loss=0.22320351004600525
Iteration 195600, loss=0.4666796028614044
Iteration 195700, loss=1.192093321833454e-07
Iteration 195800, loss=0.38635215163230896
Iteration 195900, loss=0.26809409260749817
Iteration 196000, loss=0.3562127947807312
Iteration 196100, loss=0.8865019083023071
Iteration 196200, loss=0.30241888761520386
Iteration 196300, loss=1.192093321833454e-07
Iteration 196400, loss=0.7073706984519958
Iteration 196500, loss=0.12897416949272156
Iteration 196600, loss=1.3813974857330322
Iteration 196700, loss=0.09706989675760269
Iteration 196800, loss=0.366625040769577
Iteration 196900, loss=2.66355562210083
Iteration 197000, loss=1.192093321833454e-07
Iteration 197100, loss=0.3326330780982971
Iteration 197200, loss=0.33779585361480713
Iteration 197300, loss=3.4928936656797305e-05
Iteration 197400, loss=1.192093321833454e-07
Iteration 197500, loss=1.192093321833454e-07
Iteration 197600, loss=0.21463465690612793
Iteration 197700, loss=0.25794127583503723
Iteration 197800, loss=0.37907254695892334
Iteration 197900, loss=0.8234034776687622
Iteration 198000, loss=0.5254400372505188
Iteration 198100, loss=1.521671175956726
Iteration 198200, loss=0.001906960504129529
Iteration 198300, loss=1.617527723312378
Iteration 198400, loss=1.4389522075653076
Iteration 198500, loss=2.2678492069244385
Iteration 198600, loss=0.25118738412857056
Iteration 198700, loss=2.047602891921997
Iteration 198800, loss=0.24230502545833588
Iteration 198900, loss=1.0014232397079468
Iteration 199000, loss=2.3841885194997303e-06
Iteration 199100, loss=0.08533840626478195
Iteration 199200, loss=1.192093321833454e-07
Iteration 199300, loss=1.0904321670532227
Iteration 199400, loss=1.2531051635742188
Iteration 199500, loss=0.310019850730896
Iteration 199600, loss=0.29230818152427673
Iteration 199700, loss=0.759375810623169
Iteration 199800, loss=0.7245925068855286
Iteration 199900, loss=0.019942041486501694
Saved model to disk
